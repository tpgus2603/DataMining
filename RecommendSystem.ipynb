{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tpgus2603/DataMining/blob/main/RecommendSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lgz0JbmNwxv",
        "outputId": "04eb26b8-0044-4d48-dfa3-e121df995c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ./drive/MyDrive/json_csv_files/amazon_review2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byt5hvPQRjam",
        "outputId": "d67e499b-a9db-4f69-daa5-6bd7eb4727bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/json_csv_files/amazon_review2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "통합데이터에서 전처리하여 필요한 데이터셋 확보\n"
      ],
      "metadata": {
        "id": "AB3bSdvTjFku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "# 경로 설정\n",
        "products_file_path = './combined_data2.json'\n",
        "\n",
        "# 파일 읽기\n",
        "with open(products_file_path, 'r', encoding='utf-8') as file:\n",
        "    data = [json.loads(line) for line in file]\n",
        "\n",
        "# 리뷰를 가장 많이 남긴 유저 찾기\n",
        "user_reviews = Counter([review['user_id'] for review in data])\n",
        "most_reviewed_user = user_reviews.most_common(1)[0][0]\n",
        "\n",
        "# 가장 많은 리뷰를 남긴 유저의 리뷰 추출\n",
        "top_user_reviews = [review for review in data if review['user_id'] == most_reviewed_user]\n",
        "\n",
        "# rating이 5인 리뷰 필터링\n",
        "five_star_reviews = [review for review in top_user_reviews if review['rating'] == 5]\n",
        "\n",
        "# 카테고리별로 5개씩 선택\n",
        "categories = ['Movies_TV', 'Grocery_Gourmet_Food', 'Electronics']\n",
        "user_reviews = []\n",
        "selected_reviews = set()\n",
        "for category in categories:\n",
        "    category_reviews = [review for review in five_star_reviews if review['category'] == category]\n",
        "    selected = random.sample(category_reviews, min(5, len(category_reviews)))\n",
        "    user_reviews.extend(selected)\n",
        "    selected_reviews.update(map(json.dumps, selected))  # Use JSON string for hashing\n",
        "\n",
        "# 나머지 리뷰를 test_reviews로 분류\n",
        "test_reviews = [review for review in top_user_reviews if json.dumps(review) not in selected_reviews]\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Most reviewed user ID: {most_reviewed_user}\")\n",
        "print(f\"Total reviews by user: {len(top_user_reviews)}\")\n",
        "print(f\"Five-star reviews by user: {len(five_star_reviews)}\")\n",
        "print(f\"Selected user reviews: {len(user_reviews)}\")\n",
        "print(f\"Remaining test reviews: {len(test_reviews)}\")\n",
        "\n",
        "# 선택된 user_reviews 저장 (line JSON 형태로 저장)\n",
        "user_reviews_path = './user_reviews.json'\n",
        "with open(user_reviews_path, 'w', encoding='utf-8') as file:\n",
        "    for review in user_reviews:\n",
        "        file.write(json.dumps(review, ensure_ascii=False) + '\\n')\n",
        "\n",
        "# 나머지 test_reviews 저장 (line JSON 형태로 저장)\n",
        "test_reviews_path = './test_reviews.json'\n",
        "with open(test_reviews_path, 'w', encoding='utf-8') as file:\n",
        "    for review in test_reviews:\n",
        "        file.write(json.dumps(review, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(f\"User reviews saved to {user_reviews_path}\")\n",
        "print(f\"Test reviews saved to {test_reviews_path}\")"
      ],
      "metadata": {
        "id": "UbU8FdwNvU9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf9f33b-bad6-4786-f10b-a59748fbf854"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most reviewed user ID: AFZUK3MTBIBEDQOPAK3OATUOUKLA\n",
            "Total reviews by user: 942\n",
            "Five-star reviews by user: 645\n",
            "Selected user reviews: 15\n",
            "Remaining test reviews: 927\n",
            "User reviews saved to ./user_reviews.json\n",
            "Test reviews saved to ./test_reviews.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 설치 (필요시)\n",
        "!pip install pandas scikit-learn\n",
        "\n",
        "# 라이브러리 임포트\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kdze4FbYyzm",
        "outputId": "e3a81d82-829b-4b84-cd21-42f876c024cd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "시나리오\n",
        "1.   트위터에서 추출한 사용자의 프로필이 Movies_TV, Grocery_Gourmet_Food,Eletronics 라고 가정\n",
        "2.   해당 사용자에게 content based와 colaborative filtering을 이용하여 각각 추천"
      ],
      "metadata": {
        "id": "59uqYE1--8o4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Content based"
      ],
      "metadata": {
        "id": "s9H1E6Y35Hvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 상품 데이터 파일 경로\n",
        "products_file_path = './combined_data.json'  # 실제 경로로 변경\n",
        "products_df = pd.read_json(products_file_path, lines=True)\n",
        "\n",
        "# 원하는 카테고리 목록\n",
        "desired_categories = ['Movies_TV', 'Grocery_Gourmet_Food', 'Electronics']\n",
        "\n",
        "# 카테고리 필터링\n",
        "filtered_products_df = products_df[products_df['category'].isin(desired_categories)].copy()\n",
        "filtered_products_df = filtered_products_df[['rating', 'product_title', 'category', 'parent_asin']]\n",
        "print(\"Filtered Products DataFrame:\")\n",
        "print(filtered_products_df.head())\n",
        "\n",
        "# user_reviews 데이터 로드\n",
        "user_reviews_file_path = './user_reviews.json'  # 실제 경로로 변경\n",
        "user_reviews_df = pd.read_json(user_reviews_file_path, lines=True)\n",
        "user_reviews_df = user_reviews_df[['product_title', 'category', 'parent_asin']]\n",
        "user_reviews_df = user_reviews_df[user_reviews_df['category'].isin(desired_categories)].copy()\n",
        "print(\"User Reviews DataFrame:\")\n",
        "print(user_reviews_df.head())\n",
        "\n",
        "# test_reviews 데이터 로드\n",
        "test_reviews_file_path = './test_reviews.json'  # 실제 경로로 변경\n",
        "test_reviews_df = pd.read_json(test_reviews_file_path, lines=True)\n",
        "test_reviews_df = test_reviews_df[['product_title', 'category', 'parent_asin']]\n",
        "test_reviews_df = test_reviews_df[test_reviews_df['category'].isin(desired_categories)].copy()\n",
        "print(\"Test Reviews DataFrame:\")\n",
        "print(test_reviews_df.head())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def combine_product_title(df):\n",
        "    combined = df['product_title'].fillna('')\n",
        "    # 빈 문자열을 'No Title'로 대체\n",
        "    combined = combined.apply(lambda x: x if x.strip() else 'No Title')\n",
        "    return combined\n",
        "# test_reviews를 Train/Val로 분할 (7:3)\n",
        "train_reviews, val_reviews = train_test_split(test_reviews_df, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "excluded_asins = set(train_reviews['parent_asin'])\n",
        "filtered_products_df = filtered_products_df[~filtered_products_df['parent_asin'].isin(excluded_asins)]\n",
        "\n",
        "print(f\"Excluded {len(excluded_asins)} ASINs from the combined data.\")\n",
        "\n",
        "\n",
        "\n",
        "# 평가 함수들\n",
        "def precision_at_k(recommended_asins, val_asins, k=5):\n",
        "    recommended_top_k = recommended_asins[:k]\n",
        "    relevant = [asin for asin in recommended_top_k if asin in val_asins]\n",
        "    precision = len(relevant) / k\n",
        "    return precision\n",
        "\n",
        "def recall_at_k(recommended_asins, val_asins, k=5):\n",
        "    recommended_top_k = recommended_asins[:k]\n",
        "    relevant = [asin for asin in recommended_top_k if asin in val_asins]\n",
        "    recall = len(relevant) / len(val_asins) if len(val_asins) > 0 else 0\n",
        "    return recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2YI2fTtfb-y",
        "outputId": "3fd7eeae-301c-4653-c994-571beeffccd9"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Products DataFrame:\n",
            "       rating    product_title   category parent_asin\n",
            "29669       5      Sneaky Pete  Movies_TV  B013488XFS\n",
            "29670       5  Creative Galaxy  Movies_TV  B00CB6VTDS\n",
            "29671       3             None  Movies_TV  B096Z8Z3R6\n",
            "29672       4             None  Movies_TV  B09M14D9FZ\n",
            "29673       5             None  Movies_TV  B001H1SVZC\n",
            "User Reviews DataFrame:\n",
            "                                       product_title   category parent_asin\n",
            "0                               Temple Grandin (DVD)  Movies_TV  B0038M2AZA\n",
            "1                                               None  Movies_TV  B00YMIT76O\n",
            "2                                               None  Movies_TV  B001F8IL84\n",
            "3                                               None  Movies_TV  B00907ZZ22\n",
            "4  The Golden Compass (Widescreen Single-Disc Edi...  Movies_TV  B00139W3NE\n",
            "Test Reviews DataFrame:\n",
            "   product_title   category parent_asin\n",
            "87          None  Movies_TV  B00AY5B712\n",
            "88          None  Movies_TV  B07ZWWT77T\n",
            "89          None  Movies_TV  B07XGPXPRV\n",
            "90          None  Movies_TV  B0B12GSRKP\n",
            "91          None  Movies_TV  B00AHGUCNM\n",
            "Excluded 542 ASINs from the combined data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 추천 개수 및 평점 임계값 설정\n",
        "top_n = 3\n",
        "rating_threshold = 4.5  # 평점 임계값을 4.5 이상으로 설정\n",
        "\n",
        "def get_recommendations_pure_similarity(user_tfidf, tfidf_matrix, category_df, user_reviews_df, asin_to_index, top_n=5):\n",
        "    \"\"\"\n",
        "    순수 유사도 계산.\n",
        "    \"\"\"\n",
        "    cosine_sim_user = cosine_similarity(user_tfidf, tfidf_matrix).flatten()\n",
        "    user_asins = user_reviews_df['parent_asin'].tolist()\n",
        "    user_indices = [asin_to_index[asin] for asin in user_asins if asin in asin_to_index]\n",
        "\n",
        "    # 유사도 정렬\n",
        "    sorted_indices = cosine_sim_user.argsort()[::-1]\n",
        "    sorted_indices = [idx for idx in sorted_indices if idx not in user_indices]\n",
        "    top_indices = sorted_indices[:top_n]\n",
        "\n",
        "    # 추천 상품 반환\n",
        "    recommended_products = category_df.iloc[top_indices]\n",
        "    return recommended_products.head(top_n)\n"
      ],
      "metadata": {
        "id": "B9WNPRYwfcgi"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 추천 로직 수행\n",
        "for target_category in desired_categories:\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Category: {target_category}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 카테고리 데이터 준비\n",
        "    category_df = filtered_products_df[filtered_products_df['category'] == target_category].copy()\n",
        "    category_df['combined_text'] = combine_product_title(category_df)\n",
        "\n",
        "    # Train/Val 리뷰 데이터 필터링\n",
        "    category_train_reviews = train_reviews[train_reviews['category'] == target_category].copy()\n",
        "    category_val_reviews = val_reviews[val_reviews['category'] == target_category].copy()\n",
        "\n",
        "    category_train_reviews['combined_text'] = combine_product_title(category_train_reviews)\n",
        "    category_val_reviews['combined_text'] = combine_product_title(category_val_reviews)\n",
        "\n",
        "    # TF-IDF 벡터화\n",
        "    # TF-IDF 벡터화 개선\n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_features=20000, ngram_range=(1, 2))\n",
        "    tfidf_matrix = tfidf.fit_transform(category_df['combined_text'])\n",
        "\n",
        "    # 인덱스 재설정 및 asin_to_index 생성\n",
        "    category_df = category_df.reset_index(drop=True)\n",
        "    asin_to_index = pd.Series(category_df.index, index=category_df['parent_asin']).to_dict()\n",
        "\n",
        "    print(\"TF-IDF Matrix Shape:\", tfidf_matrix.shape)\n",
        "\n",
        "    # 평점 기준 필터링\n",
        "    high_rating_products_df = category_df[category_df['rating'] >= rating_threshold].copy()\n",
        "    print(f\"Number of products with rating >= {rating_threshold} in {target_category}: {len(high_rating_products_df)}\")\n",
        "\n",
        "    # 사용자 리뷰가 있는 경우 쿼리 생성\n",
        "    if len(category_train_reviews) > 0:\n",
        "        user_query = ' '.join(category_train_reviews['combined_text'].tolist())\n",
        "        user_tfidf = tfidf.transform([user_query])\n",
        "    else:\n",
        "        user_query = ''\n",
        "        user_tfidf = tfidf.transform([''])\n",
        "\n",
        "    val_asins = category_val_reviews['parent_asin'].unique().tolist()\n",
        "\n",
        "    # 순수 유사도 기반 추천\n",
        "    recommended_products_similarity = get_recommendations_pure_similarity(\n",
        "        user_tfidf, tfidf_matrix, category_df, category_train_reviews, asin_to_index, top_n=top_n\n",
        "    )\n",
        "    recommended_asins_similarity = recommended_products_similarity['parent_asin'].tolist()\n",
        "    print(recommended_asins_similarity)\n",
        "    precision_sim = precision_at_k(recommended_asins_similarity, val_asins, k=top_n)\n",
        "    recall_sim = recall_at_k(recommended_asins_similarity, val_asins, k=top_n)\n",
        "\n",
        "    print(\"순수 유사도 기반 추천 성능:\")\n",
        "    print(f\"Precision@{top_n}: {precision_sim}, Recall@{top_n}: {recall_sim}\")\n"
      ],
      "metadata": {
        "id": "063zzAptflAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec61760f-f6f9-4757-e0bc-098ff398cbbb"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Category: Movies_TV\n",
            "==================================================\n",
            "TF-IDF Matrix Shape: (9756, 13956)\n",
            "Number of products with rating >= 4.5 in Movies_TV: 6177\n",
            "['B08YN29JJR', 'B00T6UD7BY', 'B00AALUFFY']\n",
            "순수 유사도 기반 추천 성능:\n",
            "Precision@3: 0.3333333333333333, Recall@3: 0.012048192771084338\n",
            "\n",
            "==================================================\n",
            "Category: Grocery_Gourmet_Food\n",
            "==================================================\n",
            "TF-IDF Matrix Shape: (3489, 20000)\n",
            "Number of products with rating >= 4.5 in Grocery_Gourmet_Food: 2191\n",
            "['B006OCW7DQ', 'B07FWCVP68', 'B074H7KL3S']\n",
            "순수 유사도 기반 추천 성능:\n",
            "Precision@3: 0.0, Recall@3: 0.0\n",
            "\n",
            "==================================================\n",
            "Category: Electronics\n",
            "==================================================\n",
            "TF-IDF Matrix Shape: (5394, 20000)\n",
            "Number of products with rating >= 4.5 in Electronics: 3529\n",
            "['B094NMVYKT', 'B087GCGWXS', 'B01MQRGROQ']\n",
            "순수 유사도 기반 추천 성능:\n",
            "Precision@3: 0.0, Recall@3: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mu_lyCWXt_uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 리뷰 기반 추천 (성능 평가 없음)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"User Review 기반 추천 (성능평가 없음)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 특정 사용자 데이터\n",
        "user_reviews_df['combined_text'] = combine_product_title(user_reviews_df)\n",
        "\n",
        "for target_category in desired_categories:\n",
        "    print(\"\\nCategory:\", target_category)\n",
        "    category_df = filtered_products_df[filtered_products_df['category'] == target_category].copy()\n",
        "    category_df['combined_text'] = combine_product_title(category_df)\n",
        "\n",
        "    # TF-IDF 벡터화 (max_features 줄임)\n",
        "    tfidf = TfidfVectorizer(stop_words=None, max_features=5000)  # 스탑워드 제거하지 않음\n",
        "    tfidf_matrix = tfidf.fit_transform(category_df['combined_text'])\n",
        "\n",
        "    # 인덱스 재설정 및 asin_to_index 생성\n",
        "    category_df = category_df.reset_index(drop=True)\n",
        "    asin_to_index = pd.Series(category_df.index, index=category_df['parent_asin']).to_dict()\n",
        "\n",
        "    # 평점 기준 필터링\n",
        "    high_rating_products_df = category_df[category_df['rating'] >= rating_threshold].copy()\n",
        "\n",
        "    # 사용자 전체 리뷰 텍스트로 TF-IDF 벡터 생성\n",
        "    user_query_all = ' '.join(user_reviews_df['combined_text'].tolist())\n",
        "    user_tfidf_all = tfidf.transform([user_query_all])\n",
        "    # 순수 유사도 기반 추천 (user_review)\n",
        "    recommended_products_similarity_user = get_recommendations_pure_similarity(\n",
        "        user_tfidf_all, tfidf_matrix, category_df, user_reviews_df, asin_to_index, top_n=top_n\n",
        "    )\n",
        "    print(\"User Review 기반 순수 유사도 추천 상품:\")\n",
        "    if not recommended_products_similarity_user.empty:\n",
        "        print(recommended_products_similarity_user[['parent_asin', 'product_title', 'category']])\n",
        "    else:\n",
        "        print(\"추천 없음\")"
      ],
      "metadata": {
        "id": "XAjPaWPT5AMA",
        "outputId": "fd8d87fb-5d56-4909-9b95-30afc0c2e7e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "User Review 기반 추천 (성능평가 없음)\n",
            "==================================================\n",
            "\n",
            "Category: Movies_TV\n",
            "User Review 기반 순수 유사도 추천 상품:\n",
            "     parent_asin                                      product_title   category\n",
            "4730  B003L77G7E                 Two and a Half Men: Season 8 [DVD]  Movies_TV\n",
            "7666  B005FISCFW                       Two and a Half Men: Season 9  Movies_TV\n",
            "3619  B00CRVL5ZE  X-Files: The Complete TV Series and Movie Coll...  Movies_TV\n",
            "\n",
            "Category: Grocery_Gourmet_Food\n",
            "User Review 기반 순수 유사도 추천 상품:\n",
            "     parent_asin                                      product_title  \\\n",
            "2827  B01H7AAWRQ  LANGRIA 3-Inch Gel-Infused Memory Foam Mattres...   \n",
            "3188  B07NQDLF47  365 by Whole Foods Market, Organic Baby Bella ...   \n",
            "2497  B00IJHU45M  Honest Tea Organic Fair Trade Half Tea & Half ...   \n",
            "\n",
            "                  category  \n",
            "2827  Grocery_Gourmet_Food  \n",
            "3188  Grocery_Gourmet_Food  \n",
            "2497  Grocery_Gourmet_Food  \n",
            "\n",
            "Category: Electronics\n",
            "User Review 기반 순수 유사도 추천 상품:\n",
            "     parent_asin                                      product_title  \\\n",
            "275   B07ZZVX1F2  Fire TV Stick with Alexa Voice Remote (include...   \n",
            "1464  B07ZZVX1F2  Fire TV Stick with Alexa Voice Remote (include...   \n",
            "3079  B0791TX5P5  Fire TV Stick streaming device with Alexa buil...   \n",
            "\n",
            "         category  \n",
            "275   Electronics  \n",
            "1464  Electronics  \n",
            "3079  Electronics  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# ============================================================\n",
        "# 1. 데이터 로드 및 필터링\n",
        "# ============================================================\n",
        "# 파일 경로 (예시)\n",
        "user_review_path = './user_reviews.json'   # 사용자가 평가한\n",
        "product_data_path = './combined_data2.json'     # 전체 상품 데이터 (약 6만행)\n",
        "\n",
        "# 카테고리 필터링 대상\n",
        "valid_categories = ['Movies_TV', 'Grocery_Gourmet_Food', 'Electronics']\n",
        "\n",
        "# 사용자 리뷰 로드\n",
        "with open(user_review_path, 'r', encoding='utf-8') as f:\n",
        "    user_data = [json.loads(line) for line in f]\n",
        "\n",
        "user_df = pd.DataFrame(user_data)\n",
        "\n",
        "# 전체 상품 데이터 로드\n",
        "with open(product_data_path, 'r', encoding='utf-8') as f:\n",
        "    product_data = [json.loads(line) for line in f]\n",
        "\n",
        "product_df = pd.DataFrame(product_data)\n",
        "\n",
        "# 유효 카테고리 필터링\n",
        "product_df = product_df[product_df['category'].isin(valid_categories)].copy()\n",
        "\n",
        "# ============================================================\n",
        "# 2. 필요한 열만 남기기\n",
        "# title, text, helpful_vote, verified_purchase, product_title, category, parent_asin 열만 유지\n",
        "# rating이 있는 경우 rating 열도 유지 (rating 기반 필터링용)\n",
        "# 이외 열 제거\n",
        "# ============================================================\n",
        "required_columns = ['rating','title','text','helpful_vote','verified_purchase','product_title','category','parent_asin']\n",
        "product_df = product_df[[col for col in product_df.columns if col in required_columns]]\n",
        "\n",
        "# 사용자 데이터도 동일하게 필요한 열만 유지 (rating이 있다면 유지, 없으면 제외)\n",
        "user_required_cols = ['rating','title','text','helpful_vote','verified_purchase','product_title','category','parent_asin']\n",
        "user_df = user_df[[col for col in user_df.columns if col in user_required_cols and col in user_df.columns]]\n",
        "\n",
        "# rating 정보가 없는 경우 대비(필요시 rating이 없으면 NaN처리, float 변환)\n",
        "if 'rating' in user_df.columns:\n",
        "    user_df['rating'] = pd.to_numeric(user_df['rating'], errors='coerce')\n",
        "if 'rating' in product_df.columns:\n",
        "    product_df['rating'] = pd.to_numeric(product_df['rating'], errors='coerce')\n",
        "\n",
        "# ============================================================\n",
        "# 3. 컨텐츠 기반 필터링을 위한 전처리\n",
        "# 텍스트 결합: title, text, helpful_vote, verified_purchase, product_title\n",
        "# 이들의 정보를 하나의 텍스트로 합쳐 TF-IDF 벡터화에 활용\n",
        "# ============================================================\n",
        "def combine_features(row):\n",
        "    # Null 값 처리\n",
        "    t = str(row.get('title', ''))\n",
        "    txt = str(row.get('text', ''))\n",
        "    hv = str(row.get('helpful_vote', ''))\n",
        "    vp = str(row.get('verified_purchase', ''))\n",
        "    pt = str(row.get('product_title', ''))\n",
        "    combined = ' '.join([t, txt, hv, vp, pt])\n",
        "    return combined\n",
        "\n",
        "product_df['combined_text'] = product_df.apply(combine_features, axis=1)\n",
        "user_df['combined_text'] = user_df.apply(combine_features, axis=1)\n",
        "\n",
        "# ============================================================\n",
        "# 4. TF-IDF 벡터화\n",
        "# 대규모 데이터에 대해 max_features 조정 가능\n",
        "# ============================================================\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=20000)\n",
        "tfidf_matrix = tfidf.fit_transform(product_df['combined_text'])\n",
        "\n",
        "# ASIN -> 인덱스 매핑\n",
        "product_df = product_df.reset_index(drop=True)\n",
        "asin_to_index = pd.Series(product_df.index, index=product_df['parent_asin']).to_dict()\n",
        "\n",
        "# ============================================================\n",
        "# 5. rating 기반 필터링\n",
        "# 사용자 리뷰 중 rating이 5인 경우를 추출한 뒤, 이와 유사한 제품 추천\n",
        "# rating 없이 순수 유사도 기반 추천도 구현\n",
        "# ============================================================\n",
        "\n",
        "# 사용자 rating==5인 리뷰 추출\n",
        "if 'rating' in user_df.columns:\n",
        "    high_rating_user_reviews = user_df[user_df['rating'] == 5].copy()\n",
        "else:\n",
        "    # rating 정보가 없는 경우 빈 DataFrame\n",
        "    high_rating_user_reviews = pd.DataFrame(columns=user_df.columns)\n",
        "\n",
        "# 사용자가 평가한 제품 목록\n",
        "user_asins = user_df['parent_asin'].unique().tolist()\n",
        "\n",
        "# 사용자 전체 리뷰 텍스트 합치기 (순수 유사도 방식)\n",
        "user_query_all = ' '.join(user_df['combined_text'].tolist())\n",
        "user_tfidf_all = tfidf.transform([user_query_all])\n",
        "\n",
        "# rating == 5 인 제품만을 바탕으로 추천을 수행하는 경우:\n",
        "# 사용자 rating==5인 리뷰들의 combined_text를 모두 합쳐 유사 제품 추천\n",
        "if len(high_rating_user_reviews) > 0:\n",
        "    high_rating_query = ' '.join(high_rating_user_reviews['combined_text'].tolist())\n",
        "    high_rating_tfidf = tfidf.transform([high_rating_query])\n",
        "else:\n",
        "    high_rating_tfidf = None\n",
        "\n",
        "# ============================================================\n",
        "# 6. 추천 함수 정의\n",
        "# ============================================================\n",
        "def recommend_by_pure_similarity(user_tfidf, tfidf_matrix, product_df, user_asins, top_n=10):\n",
        "    if user_tfidf is None or user_tfidf.shape[0] == 0:\n",
        "        return pd.DataFrame()\n",
        "    # 사용자 쿼리와 모든 제품간 유사도 계산\n",
        "    cosine_sim = cosine_similarity(user_tfidf, tfidf_matrix).flatten()\n",
        "    # 이미 사용자에게 있는 제품 제외\n",
        "    all_indices = np.argsort(cosine_sim)[::-1]\n",
        "    filtered_indices = [idx for idx in all_indices if product_df.loc[idx, 'parent_asin'] not in user_asins]\n",
        "    top_indices = filtered_indices[:top_n]\n",
        "    return product_df.iloc[top_indices].copy()\n",
        "\n",
        "def recommend_by_rating_filter(user_tfidf, tfidf_matrix, product_df, user_asins, rating_threshold=5, top_n=10):\n",
        "    if user_tfidf is None or user_tfidf.shape[0] == 0:\n",
        "        return pd.DataFrame()\n",
        "    # rating threshold 적용 (여기서는 rating == 5인 경우)\n",
        "    high_rating_products = product_df[product_df['rating'] == rating_threshold].copy()\n",
        "    if high_rating_products.empty:\n",
        "        return pd.DataFrame()\n",
        "    # high_rating_products에 해당하는 인덱스만을 대상으로 유사도 계산\n",
        "    high_rating_indices = high_rating_products.index.tolist()\n",
        "    cosine_sim = cosine_similarity(user_tfidf, tfidf_matrix[high_rating_indices]).flatten()\n",
        "    sorted_indices = np.argsort(cosine_sim)[::-1]\n",
        "    # 이미 가진 제품 제외\n",
        "    result_indices = [high_rating_indices[i] for i in sorted_indices if product_df.loc[high_rating_indices[i],'parent_asin'] not in user_asins]\n",
        "    top_indices = result_indices[:top_n]\n",
        "    return product_df.iloc[top_indices].copy()\n",
        "\n",
        "# ============================================================\n",
        "# 7. 추천 결과 확인\n",
        "# ============================================================\n",
        "print(\"===== 순수 유사도 기반 추천 (rating 고려 X) =====\")\n",
        "pure_sim_recommendations = recommend_by_pure_similarity(user_tfidf_all, tfidf_matrix, product_df, user_asins, top_n=5)\n",
        "if pure_sim_recommendations.empty:\n",
        "    print(\"추천 결과 없음\")\n",
        "else:\n",
        "    print(pure_sim_recommendations[['parent_asin','product_title','category','rating']])\n",
        "\n",
        "print(\"\\n===== rating == 5 기반 필터링 후 유사도 추천 =====\")\n",
        "rating_filter_recommendations = recommend_by_rating_filter(high_rating_tfidf, tfidf_matrix, product_df, user_asins, rating_threshold=5, top_n=5)\n",
        "if rating_filter_recommendations.empty:\n",
        "    print(\"추천 결과 없음 (rating이 5인 상품 기준 추천 불가)\")\n",
        "else:\n",
        "    print(rating_filter_recommendations[['parent_asin','product_title','category','rating']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFpGRt9SuAx8",
        "outputId": "5903f30e-6823-4ac4-8296-118b1f24de17"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-83-4316a5bd29b9>:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  user_df['rating'] = pd.to_numeric(user_df['rating'], errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 순수 유사도 기반 추천 (rating 고려 X) =====\n",
            "      parent_asin                                      product_title  \\\n",
            "8402   B00FKT11ZE                                               None   \n",
            "433    B001EBV0OY                                               None   \n",
            "434    B0036BK6MW                                               None   \n",
            "460    B00EL6AAEU                                          Blackfish   \n",
            "15203  B004RO3QPQ  Cobra®️ ESD7570 - 360 Degree Detection,9 Band,...   \n",
            "\n",
            "          category  rating  \n",
            "8402     Movies_TV     5.0  \n",
            "433      Movies_TV     5.0  \n",
            "434      Movies_TV     4.0  \n",
            "460      Movies_TV     5.0  \n",
            "15203  Electronics     4.0  \n",
            "\n",
            "===== rating == 5 기반 필터링 후 유사도 추천 =====\n",
            "      parent_asin                                      product_title  \\\n",
            "8402   B00FKT11ZE                                               None   \n",
            "433    B001EBV0OY                                               None   \n",
            "460    B00EL6AAEU                                          Blackfish   \n",
            "10804  B011LQM2ZC  Dr. John's Inspired Sweets Classic Fruits Coll...   \n",
            "449    B004EPZ01G                                       Dolphin Tale   \n",
            "\n",
            "                   category  rating  \n",
            "8402              Movies_TV     5.0  \n",
            "433               Movies_TV     5.0  \n",
            "460               Movies_TV     5.0  \n",
            "10804  Grocery_Gourmet_Food     5.0  \n",
            "449               Movies_TV     5.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colaborative Filtering"
      ],
      "metadata": {
        "id": "2tXZ6rR55Beu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# local에 padnas, numpy, matplotlib, surprise, sklearn 설치필요\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "YH2Y3RN35BFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 전처리"
      ],
      "metadata": {
        "id": "xxzSpsc85pUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_review(review_path, min_user_cnt, min_review_cnt):\n",
        "    review_df = pd.read_json(review_path, lines=True)\n",
        "    filtered_review_df = review_df[[\"parent_asin\", \"rating\", \"user_id\", \"title\", \"category\", \"product_title\"]]\n",
        "    # filtered_review_df = filtered_review_df[filtered_review_df[\"category\"] == category]\n",
        "    distinct_review_df = filtered_review_df.drop_duplicates(subset=[\"user_id\", \"parent_asin\"])\n",
        "\n",
        "    review_counts = distinct_review_df[\"parent_asin\"].value_counts()\n",
        "    user_counts = distinct_review_df['user_id'].value_counts()\n",
        "\n",
        "    result_df = distinct_review_df[(\n",
        "        (distinct_review_df['user_id'].isin(user_counts[user_counts >= min_user_cnt].index)) &\n",
        "        (distinct_review_df['parent_asin'].isin(review_counts[review_counts >= min_review_cnt].index))\n",
        "    )]\n",
        "\n",
        "    # # 리뷰 개수가 많은 순으로 정렬\n",
        "    # sorted_parent_asin = result_df[\"parent_asin\"].value_counts().index\n",
        "    # result_df = result_df.set_index(\"parent_asin\").loc[sorted_parent_asin].reset_index()\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "x79bggO55OR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_predict(item_sim_df, train_matrix, k=5):\n",
        "    item_ids = train_matrix.index\n",
        "    user_ids = train_matrix.columns\n",
        "    predictions = np.zeros(train_matrix.shape)\n",
        "\n",
        "    for item_idx, item in enumerate(item_ids):\n",
        "        for user_idx, user in enumerate(user_ids):\n",
        "            user_ratings = train_matrix.iloc[:, user_idx].values  # 해당 사용자의 모든 평점\n",
        "            relevant_items = item_sim_df.iloc[item_idx].values  # 현재 아이템과 다른 아이템 간 유사도\n",
        "\n",
        "            # K개의 가장 유사한 이웃 선택\n",
        "            neighbors_idx = np.argsort(relevant_items)[-k:]\n",
        "            neighbors_sim = relevant_items[neighbors_idx]\n",
        "            neighbors_ratings = user_ratings[neighbors_idx]\n",
        "\n",
        "            # 가중합 계산\n",
        "            weighted_sum = np.dot(neighbors_sim, neighbors_ratings)\n",
        "            sim_sum = np.abs(neighbors_sim).sum()\n",
        "\n",
        "            if sim_sum > 0:\n",
        "                predictions[item_idx, user_idx] = weighted_sum / sim_sum\n",
        "            else:\n",
        "                # 유사도가 없는 경우 행 평균값으로 대체\n",
        "                row_mean = train_matrix.iloc[item_idx, :].mean()\n",
        "                predictions[item_idx, user_idx] = row_mean\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def knn_based_cf(df, org_df, k=5):\n",
        "    # 사용자-아이템 행렬 생성\n",
        "    item_user_matrix = df.pivot(index='parent_asin', columns='user_id', values='rating').fillna(0)\n",
        "    item_ids = item_user_matrix.index\n",
        "    user_ids = item_user_matrix.columns\n",
        "\n",
        "    if df.empty:\n",
        "        return \"Empty\",\"Empty\"\n",
        "\n",
        "    # 훈련-테스트 데이터 분할\n",
        "    trainset, testset = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 훈련 데이터로 사용자-아이템 행렬 생성\n",
        "    train_matrix = trainset.pivot(index='parent_asin', columns='user_id', values='rating').reindex(index=item_ids, columns=user_ids).fillna(0)\n",
        "    test_matrix = testset.pivot(index='parent_asin', columns='user_id', values='rating').reindex(index=item_ids, columns=user_ids).fillna(0)\n",
        "\n",
        "    # 아이템 기반 코사인 유사도 계산\n",
        "    item_sim_matrix = cosine_similarity(train_matrix)\n",
        "    np.fill_diagonal(item_sim_matrix, 0)  # 자신과의 유사도는 0으로 설정\n",
        "    item_sim_df = pd.DataFrame(item_sim_matrix, index=item_ids, columns=item_ids)\n",
        "\n",
        "    # 예측값 생성\n",
        "    predictions = knn_predict(item_sim_df, train_matrix, k)\n",
        "\n",
        "    # 테스트 세트에서 RMSE 계산\n",
        "    test_actual = test_matrix.values[test_matrix > 0]\n",
        "    test_predicted = predictions[test_matrix > 0]\n",
        "    rmse = sqrt(mean_squared_error(test_actual, test_predicted))\n",
        "\n",
        "    # 커버리지 계산\n",
        "    total_len = len(org_df['parent_asin'].unique())\n",
        "    non_zero_predictions = np.sum(predictions > 0)\n",
        "    coverage_value = non_zero_predictions / total_len\n",
        "    return rmse, coverage_value"
      ],
      "metadata": {
        "id": "bQO6i4H65u1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터를 전처리 할 때 파라미터로 상품별 최소 리뷰 개수와 사용자별 최소 작성 리뷰 개수를 전달해 데이터를 필터링하였다. 이는 2가지 이유가 있는데, 첫번째는 데이터의 희소성을 줄여 성능 향상을 도모하기 위해서이고, 두번째는 연산 속도를 높이기 위함이었다. 설정한 값은 각각 8로 하였다."
      ],
      "metadata": {
        "id": "k9d8neR-54rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_path = './combined_data2.json'\n",
        "review_df = pd.read_json(review_path, lines=True)\n",
        "raw_df = review_df[[\"parent_asin\", \"rating\", \"user_id\", \"title\", \"category\", \"product_title\"]]\n",
        "raw_df = raw_df.drop_duplicates(subset=[\"user_id\", \"parent_asin\"])\n",
        "review_df = preprocess_review(review_path,8,8)"
      ],
      "metadata": {
        "id": "GrAl2Hw855xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아이템-사용자 행렬에서 아이템 끼리의 코사인 유사도를 구한 후 K개의 근접한 이웃을 뽑아 평점 예측을 하였다. 성능 지표로는 정확성을 위한 테스트 셋과 예측으로 만들어진 행렬간의 RMSE와 다양성을 위한 전체 상품 수 중 몇 가지를 추천하는지 그 비율을 나타내는 Coverage 2가지를 채택하였다."
      ],
      "metadata": {
        "id": "7OG0y5AW6JaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하지만 처음 시도한 결과는 좋지 않았다. RMSE가 4.281과 Coverage가 48.61%라는 만족스럽지 못한 수치가 나왔다. 이는 사용한 샘플 데이터의 희소성이 높기 때문이라고 가정하고 이를 낮추는 것을 목표로 삼았다."
      ],
      "metadata": {
        "id": "tdw881Vz6Lz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 아이템 기반 CF 실행\n",
        "rmse,coverage_value = knn_based_cf(review_df,raw_df)\n",
        "print(\"KNN based\")\n",
        "print(f\"RMSE: {rmse:.3f}\")\n",
        "print(f\"Coverage: {coverage_value:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWe1pVbQ6PVU",
        "outputId": "ab486982-9270-4f46-aea3-0852a5b8a0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN based\n",
            "RMSE: 4.281\n",
            "Coverage: 48.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플 데이터의 희소성을 낮추기 위하여 작성한 리뷰가 많은 사용자 N명 또는 리뷰가 많았던 상품 N개를 골라 데이터를 조정하여 테스트해보았다. N을 20~50 범위에서 Gridsearch를 이용하여 가장 좋은 성능일 때의 파라미터를 찾았다. 그 결과, 인기 사용자는 22명, 인기 상품은 23개 일때 각각 RMSE가 3.808, 3.826이 나왔다. 이렇게 샘플 데이터를 필터링하여 희소성을 낮추자 RMSE 성능이 개선되었다. 하지만 N의 값이 커질수록 coverage는 감소하며 상품 추천의 다양성은 줄어들었다."
      ],
      "metadata": {
        "id": "uUOXFfR76RvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_hyperparameter_x(review_df, raw_df, y=50, x_range=(20, 50)):\n",
        "    best_rmse = float('inf')\n",
        "    best_params = {'x': None, 'rmse': None, 'coverage': None}\n",
        "    x_values = range(x_range[0], x_range[1] + 1)\n",
        "\n",
        "    for x in x_values:\n",
        "        # 상위 x명의 유저와 각 유저당 y개의 리뷰를 필터링\n",
        "        top_user_id = (\n",
        "            review_df['user_id']\n",
        "            .value_counts()\n",
        "            .head(x)\n",
        "            .index\n",
        "        )\n",
        "        filtered_df = (\n",
        "            review_df[review_df['user_id'].isin(top_user_id)]\n",
        "            .groupby('user_id')\n",
        "            .apply(lambda group: group.head(y))\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "\n",
        "        rmse, coverage_value = knn_based_cf(filtered_df, raw_df)\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_params = {\n",
        "                'x': x,\n",
        "                'rmse': rmse,\n",
        "                'coverage': coverage_value\n",
        "            }\n",
        "\n",
        "    return best_params\n",
        "\n",
        "# 사용 예제\n",
        "best_params = find_best_hyperparameter_x(review_df, raw_df, y=50, x_range=(20, 50))\n",
        "\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(f\"x: {best_params['x']}\")\n",
        "print(f\"RMSE: {best_params['rmse']:.3f}\")\n",
        "print(f\"Coverage: {best_params['coverage']:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx_XbNVs6Sn_",
        "outputId": "2ecde2c0-bafa-4d12-c54a-c8e832462049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-36-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "x: 22\n",
            "RMSE: 3.808\n",
            "Coverage: 0.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_hyperparameter_x(review_df, raw_df, y=50, x_range=(20, 50)):\n",
        "    best_rmse = float('inf')\n",
        "    best_params = {'x': None, 'rmse': None, 'coverage': None}\n",
        "\n",
        "    x_values = range(x_range[0], x_range[1] + 1)\n",
        "\n",
        "    for x in x_values:\n",
        "        # 상위 N개의 상품과 각 상품의 y개를 필터링\n",
        "        top_item_id = (\n",
        "            review_df['parent_asin']\n",
        "            .value_counts()\n",
        "            .head(x)\n",
        "            .index\n",
        "        )\n",
        "        filtered_df = (\n",
        "            review_df[review_df['parent_asin'].isin(top_item_id)]\n",
        "            .groupby('parent_asin')\n",
        "            .apply(lambda group: group.head(y))\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "\n",
        "        rmse, coverage_value = knn_based_cf(filtered_df, raw_df)\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_params = {\n",
        "                'x': x,\n",
        "                'rmse': rmse,\n",
        "                'coverage': coverage_value\n",
        "            }\n",
        "\n",
        "    return best_params\n",
        "\n",
        "# 사용 예제\n",
        "best_params = find_best_hyperparameter_x(review_df, raw_df, y=50, x_range=(20, 50))\n",
        "\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(f\"x: {best_params['x']}\")\n",
        "print(f\"RMSE: {best_params['rmse']:.3f}\")\n",
        "print(f\"Coverage: {best_params['coverage']:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F31g69SM6YNW",
        "outputId": "961975b0-2edd-4b37-9794-a9496452a3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-37-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "x: 23\n",
            "RMSE: 3.826\n",
            "Coverage: 3.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**surprise 라이브러리 이용**\n",
        "\n",
        "GridSearch로도 RMSE에서 좋은 성능을 얻지 못하자 자체 구현한 알고리즘의 최적화 부분에서 문제가 있을 거라는 가설을 세웠다. 그래서 surprise 라이브러리를 사용하여 다시 진행해보았다."
      ],
      "metadata": {
        "id": "XX8qcBWX7EMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise\n",
        "from surprise import Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "def prepare_data(df):\n",
        "    reader = Reader(rating_scale=(1, 5))  # 평점 범위 지정\n",
        "    data = Dataset.load_from_df(df[[\"user_id\", \"parent_asin\", \"rating\"]], reader)\n",
        "    return data\n",
        "\n",
        "def coverage(predictions, total_len):\n",
        "    recommended_items = set([pred.iid for pred in predictions])\n",
        "    return len(recommended_items) / total_len\n",
        "\n",
        "def knn_based_cf_surprise(df,org_df):\n",
        "    data = prepare_data(df)\n",
        "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 코사인 유사도를 사용한 아이템 기반 CF 모델 설정\n",
        "    sim_options = {\n",
        "        \"name\": \"cosine\",\n",
        "        \"user_based\": False,\n",
        "    }\n",
        "    algo = KNNBasic(sim_options=sim_options)\n",
        "    algo.fit(trainset)\n",
        "\n",
        "    predictions = algo.test(testset)\n",
        "    # RMSE 계산\n",
        "    rmse = accuracy.rmse(predictions)\n",
        "\n",
        "    # Coverage 계산\n",
        "    total_len = len(org_df['parent_asin'].unique())\n",
        "    coverage_value = coverage(predictions, total_len)\n",
        "\n",
        "    return rmse,coverage_value,trainset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "likWyAKG7Ox5",
        "outputId": "a997a20a-1ac7-4b41-b86a-3a0b28d566be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: surprise in /usr/local/lib/python3.10/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (from surprise) (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "surprise 라이브러리를 사용하니 RMSE가 1.219으로 줄었으나 coverage가 0.36%로 매우 낮아졌다. 이는 처음에 데이터 전처리를 할 때 파라미터(상품별 최소 리뷰 개수, 사용자별 최소 작성 리뷰 개수)를 각각 8개로 설정해 필터링했는데 surprise 라이브러리를 사용하니 다양성이 크게 훼손되었다. 하지만 RMSE 성능이 개선되었고 연산속도가 빨라져 더 큰 데이터를 처리할 수 있다고 판단하여 데이터 전처리 과정에서 파라미터를 2,2로 설정하여 성능을 다시 측정하였다. 그 결과 RMSE가 1.242, Coverage가 5.00%라는 좋은 성능을 얻을 수 있었다."
      ],
      "metadata": {
        "id": "_reVy7DD7hRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse,coverage_value,trainset = knn_based_cf_surprise(review_df,raw_df)\n",
        "print(\"KNN based\")\n",
        "print(f\"RMSE: {rmse:.3f}\")\n",
        "print(f\"Coverage: {coverage_value:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhrnRFNa7lcG",
        "outputId": "b91d744d-111e-494e-cba6-e4e22d8359ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.2190\n",
            "KNN based\n",
            "RMSE: 1.219\n",
            "Coverage: 0.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_review_df = preprocess_review(review_path,2,2)\n",
        "rmse,coverage_value,trainset = knn_based_cf_surprise(new_review_df,raw_df)\n",
        "print(\"KNN based\")\n",
        "print(f\"RMSE: {rmse:.3f}\")\n",
        "print(f\"Coverage: {coverage_value:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7LBXo8k7mk4",
        "outputId": "8048c216-6f4e-438f-fe55-9524a7bb7fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.2421\n",
            "KNN based\n",
            "RMSE: 1.242\n",
            "Coverage: 5.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 추가적인 성능 개선을 위하여 KNN에 기반한 Memory based 방식의 CF가 아닌, SVD에 기반한 Model based 방식의 CF를 적용해보았다. 그 결과 RMSE가 1.143으로 개선된 것을 확인할 수 있었다. 이는 데이터의 희소성을 해소했기 때문이다."
      ],
      "metadata": {
        "id": "lrSiiwpn7sLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD\n",
        "\n",
        "def svd_based_cf(df,org_df):\n",
        "    data = prepare_data(df)\n",
        "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "    algo = SVD(n_factors=10, random_state=42)\n",
        "    algo.fit(trainset)\n",
        "    predictions = algo.test(testset)\n",
        "\n",
        "    # RMSE 계산\n",
        "    rmse = accuracy.rmse(predictions)\n",
        "\n",
        "    # Coverage 계산\n",
        "    total_len = len(org_df['parent_asin'].unique())\n",
        "    coverage_value = coverage(predictions, total_len)\n",
        "    return rmse, coverage_value\n",
        "\n",
        "rmse,coverage_value = svd_based_cf(new_review_df,raw_df)\n",
        "print(\"SVD based\")\n",
        "print(f\"RMSE: {rmse:.3f}\")\n",
        "print(f\"Coverage: {coverage_value:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSEiyr-U7tR8",
        "outputId": "aeea4169-ca18-4151-89f6-439a38fa281b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1.1430\n",
            "SVD based\n",
            "RMSE: 1.143\n",
            "Coverage: 5.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제 시나리오\n",
        "\n",
        "1. 카테고리 입력\n",
        "2. 해당 카테고리 인기 상품 5개 추출\n",
        "3. 5개 상품에 대하여 각각 추천하여 유사도 높은 순으로 정렬"
      ],
      "metadata": {
        "id": "oGdIvekD72eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력한 카테고리에서 인기 상품을 추천하는 함수\n",
        "def CategoryBasedRecommend(review_df, targetCategory, top_n=5):\n",
        "\n",
        "    filtered_df = review_df[review_df[\"category\"] == targetCategory]\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        print(f\"카테고리 '{targetCategory}'에 해당하는 데이터가 없습니다.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    popular_items = (\n",
        "        filtered_df.groupby([\"parent_asin\", \"category\",\"product_title\"])\n",
        "        .agg(avg_rating=(\"rating\", \"mean\"), num_reviews=(\"user_id\", \"count\"))\n",
        "        .reset_index()\n",
        "        .sort_values(by=[\"num_reviews\", \"avg_rating\"], ascending=[False, False])\n",
        "    )\n",
        "    top_items = popular_items.head(top_n)\n",
        "    return top_items"
      ],
      "metadata": {
        "id": "qQfZBXuz75FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 상품과 관련된 추천 5개 생성\n",
        "def recommend_related_items(df, target_item, top_n=5):\n",
        "    data = prepare_data(df)\n",
        "    trainset = data.build_full_trainset()\n",
        "    algo = SVD(n_factors=50, random_state=42)\n",
        "    algo.fit(trainset)\n",
        "    item_factors = algo.qi\n",
        "    item_ids = trainset._raw2inner_id_items.keys()\n",
        "\n",
        "    item_factors_df = pd.DataFrame(item_factors, index=item_ids)\n",
        "\n",
        "    if target_item not in item_factors_df.index:\n",
        "        raise ValueError(f\"Target item {target_item} not found in training data.\")\n",
        "    target_vector = item_factors_df.loc[target_item].values.reshape(1, -1)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarities = cosine_similarity(target_vector, item_factors_df.values).flatten()\n",
        "\n",
        "    # 유사도를 데이터프레임으로 변환\n",
        "    similarity_df = pd.DataFrame({\n",
        "        \"parent_asin\": item_factors_df.index,\n",
        "        \"similarity\": similarities\n",
        "    })\n",
        "\n",
        "    # 대상 아이템 제외 및 상위 N개 추천\n",
        "    top_related_items = similarity_df[similarity_df[\"parent_asin\"] != target_item] \\\n",
        "        .sort_values(by=\"similarity\", ascending=False) \\\n",
        "        .head(top_n)\n",
        "\n",
        "    # 추천 결과에 상품 정보 병합\n",
        "    related_items_df = top_related_items.merge(\n",
        "        df[[\"parent_asin\", \"product_title\", \"category\"]].drop_duplicates(), on=\"parent_asin\", how=\"left\"\n",
        "    )\n",
        "\n",
        "    return related_items_df"
      ],
      "metadata": {
        "id": "D5dA6Thp755j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_category in desired_categories:\n",
        "  top_items = CategoryBasedRecommend(new_review_df,input_category)\n",
        "  recommend_result = []\n",
        "  for _, row in top_items.iterrows():\n",
        "      target_item = row[\"parent_asin\"]\n",
        "      target_category = row[\"category\"]\n",
        "      result = recommend_related_items(new_review_df, target_item)\n",
        "      for _, recommend_row in result.iterrows():\n",
        "          recommended_asin = recommend_row[\"parent_asin\"]\n",
        "          if recommended_asin not in [item[\"parent_asin\"] for item in recommend_result]:\n",
        "              recommend_result.append({\n",
        "                  \"parent_asin\": recommended_asin,\n",
        "                  \"product_title\": recommend_row[\"product_title\"],\n",
        "                  \"category\": recommend_row[\"category\"],\n",
        "                  \"similarity\": recommend_row[\"similarity\"]\n",
        "              })\n",
        "\n",
        "  sorted_recommendations = sorted(recommend_result, key=lambda x: x[\"similarity\"], reverse=True)[:5]\n",
        "\n",
        "  print(\"Input Category : \",input_category,\"\\n\")\n",
        "\n",
        "  print(\"Top 5 Recommended Items:\")\n",
        "  for item in sorted_recommendations:\n",
        "      print(f\"Parent ASIN: {item['parent_asin']}\")\n",
        "      print(f\"Product Title: {item['product_title']}\")\n",
        "      print(f\"Category: {item['category']}\")\n",
        "      print(f\"Similarity: {item['similarity']:.3f}\")\n",
        "      print(\"-\" * 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cBXRLEl78YL",
        "outputId": "be39a534-e02b-4c85-f875-f236639e06af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Category :  Movies_TV \n",
            "\n",
            "Top 5 Recommended Items:\n",
            "Parent ASIN: B00OH8SGFC\n",
            "Product Title: Vera\n",
            "Category: Movies_TV\n",
            "Similarity: 0.524\n",
            "------------------------------\n",
            "Parent ASIN: B07JZB74TD\n",
            "Product Title: My Talking Tom 2\n",
            "Category: Software\n",
            "Similarity: 0.516\n",
            "------------------------------\n",
            "Parent ASIN: B077D4921Z\n",
            "Product Title: Magnet Eyelashes-Dual Magnetic False Eyelashes with NO GLUE 3D Fiber Reusable Best Fake Lashes Extension for Natural Look,Perfect for Deep Set Eyes (-2 Pair/8 Pieces)\n",
            "Category: Beauty\n",
            "Similarity: 0.501\n",
            "------------------------------\n",
            "Parent ASIN: B00A0RUGPM\n",
            "Product Title: KISS Heat Resistant Hair Tools Mat, 100% Silicone Protection up to 480°F, Non-Slip, Weight 0.45 Pounds, 10 inches x 10 inches, Black\n",
            "Category: Beauty\n",
            "Similarity: 0.488\n",
            "------------------------------\n",
            "Parent ASIN: B001F42MKG\n",
            "Product Title: Logitech Trackman Marble Trackball – Wired USB Ergonomic Mouse for Computers, with 4 Programmable Buttons, Dark Gray\n",
            "Category: Electronics\n",
            "Similarity: 0.484\n",
            "------------------------------\n",
            "Input Category :  Grocery_Gourmet_Food \n",
            "\n",
            "Top 5 Recommended Items:\n",
            "Parent ASIN: B072V478NR\n",
            "Product Title: Amazon Basics Carrying Case for Nintendo Switch - Black\n",
            "Category: Video_Games\n",
            "Similarity: 0.582\n",
            "------------------------------\n",
            "Parent ASIN: B0BNTLCS7N\n",
            "Product Title: Annie Chun's - Noodle Soup Bowl, Japanese Style Miso, Instant & Microwaveable Noodles, Vegan, Hearty and Delicious, 5.9 Oz (Pack of 6)\n",
            "Category: Grocery_Gourmet_Food\n",
            "Similarity: 0.520\n",
            "------------------------------\n",
            "Parent ASIN: B01FF96B94\n",
            "Product Title: CARNATION Half n Half 360x .304 fl oz US\n",
            "Category: Grocery_Gourmet_Food\n",
            "Similarity: 0.499\n",
            "------------------------------\n",
            "Parent ASIN: B07MQFPDSS\n",
            "Product Title: Fitbit Inspire Fitness Tracker, One Size (S and L Bands Included)\n",
            "Category: Sports_Outdoors\n",
            "Similarity: 0.489\n",
            "------------------------------\n",
            "Parent ASIN: B08SG6K56D\n",
            "Product Title: ZIXMMO OEM Quality 28in + 16in Premium All-Season Windshield Wiper Blades for Original Equipment Replacement(Set of 2)\n",
            "Category: Car\n",
            "Similarity: 0.485\n",
            "------------------------------\n",
            "Input Category :  Electronics \n",
            "\n",
            "Top 5 Recommended Items:\n",
            "Parent ASIN: B00LML7GJY\n",
            "Product Title: Wagan EL8324 Wagan Tech Solar e Charger Dex\n",
            "Category: Car\n",
            "Similarity: 0.582\n",
            "------------------------------\n",
            "Parent ASIN: B07VGQFZB7\n",
            "Product Title: Louis Pelle Hand Painted Leather Triple Zip Pocket Crossbody Bag For Women Original Art Work\n",
            "Category: Fashion\n",
            "Similarity: 0.522\n",
            "------------------------------\n",
            "Parent ASIN: B07T64WW7P\n",
            "Product Title: ORDA Wireless Controller Compatible with PS4, Wireless Gamepad for PC (7/8/8.1/10) with Vibration and Audio Function, Mini LED Indicator, USB Cable and Anti-Slip\n",
            "Category: Video_Games\n",
            "Similarity: 0.518\n",
            "------------------------------\n",
            "Parent ASIN: B07L1XW8W3\n",
            "Product Title: 4 XL Surprise Bath Bombs Gift Set - Made in The USA - Kids Bath Bombs with Surprises Inside - Bath Bombs Gift Set for Girls & Boys -\n",
            "Category: Beauty\n",
            "Similarity: 0.512\n",
            "------------------------------\n",
            "Parent ASIN: B00KVQQHNM\n",
            "Product Title: Turtle Beach Ear Force Heroes of the Storm Gaming Headset for PC and Mobile Devices\n",
            "Category: Video_Games\n",
            "Similarity: 0.502\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}
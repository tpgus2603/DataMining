{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tpgus2603/DataMining/blob/main/RecommendSystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lgz0JbmNwxv",
        "outputId": "5cf9f462-0423-40c4-de78-bf961ee47291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ./drive/MyDrive/json_csv_files/amazon_review2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byt5hvPQRjam",
        "outputId": "c4a50eee-becd-48af-d88c-4b7e1f73eb76"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: './drive/MyDrive/json_csv_files/amazon_review2'\n",
            "/content/drive/MyDrive/json_csv_files/amazon_review2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UbU8FdwNvU9T"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 설치 (필요시)\n",
        "!pip install pandas scikit-learn\n",
        "\n",
        "# 라이브러리 임포트\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kdze4FbYyzm",
        "outputId": "763c1b1d-6560-4a49-ab95-faf9e6ea06a1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "시나리오\n",
        "1.   트위터에서 추출한 사용자의 프로필이 Movies_TV, Grocery_Gourmet_Food,Eletronics 라고 가정\n",
        "2.   해당 사용자에게 content based와 colaborative filtering을 이용하여 각각 추천"
      ],
      "metadata": {
        "id": "59uqYE1--8o4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Content based"
      ],
      "metadata": {
        "id": "s9H1E6Y35Hvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# 상품 데이터 파일 경로\n",
        "products_file_path = './combined_data2.json'  # 실제 경로로 변경\n",
        "products_df = pd.read_json(products_file_path, lines=True)\n",
        "\n",
        "# 원하는 카테고리 목록\n",
        "desired_categories = ['Movies_TV', 'Grocery_Gourmet_Food', 'Electronics']\n",
        "\n",
        "# 카테고리 필터링\n",
        "filtered_products_df = products_df[products_df['category'].isin(desired_categories)].copy()\n",
        "filtered_products_df = filtered_products_df[['rating', 'product_title', 'category', 'parent_asin']]\n",
        "print(\"Filtered Products DataFrame:\")\n",
        "print(filtered_products_df.head())\n",
        "\n",
        "# user_reviews 데이터 로드\n",
        "user_reviews_file_path = './user_reviews.json'  # 실제 경로로 변경\n",
        "user_reviews_df = pd.read_json(user_reviews_file_path, lines=True)\n",
        "user_reviews_df = user_reviews_df[['product_title', 'category', 'parent_asin']]\n",
        "user_reviews_df = user_reviews_df[user_reviews_df['category'].isin(desired_categories)].copy()\n",
        "print(\"User Reviews DataFrame:\")\n",
        "print(user_reviews_df.head())\n",
        "\n",
        "# test_reviews 데이터 로드\n",
        "test_reviews_file_path = './test_reviews.json'  # 실제 경로로 변경\n",
        "test_reviews_df = pd.read_json(test_reviews_file_path, lines=True)\n",
        "test_reviews_df = test_reviews_df[['product_title', 'category', 'parent_asin']]\n",
        "test_reviews_df = test_reviews_df[test_reviews_df['category'].isin(desired_categories)].copy()\n",
        "print(\"Test Reviews DataFrame:\")\n",
        "print(test_reviews_df.head())\n",
        "\n",
        "def combine_product_title(df):\n",
        "    return df['product_title'].fillna('')\n",
        "\n",
        "# test_reviews를 Train/Val로 분할 (7:3)\n",
        "train_reviews, val_reviews = train_test_split(test_reviews_df, test_size=0.3, random_state=42)\n",
        "\n",
        "# 카테고리별로 TF-IDF를 계산하기 위해 각 카테고리별로 반복 수행\n",
        "rating_threshold = 4.5  # 평점 임계값을 4.5 이상으로 설정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2YI2fTtfb-y",
        "outputId": "03f5e4ee-2c90-41b7-dd5f-6b33d4220b21"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Products DataFrame:\n",
            "       rating                                      product_title     category  \\\n",
            "40000       3  Binoculars, 12x42 Binoculars for Adults, Binoc...  Electronics   \n",
            "40001       1  Toys for 4-5 Year Old Boys, Mom&myaboys 8 X 21...  Electronics   \n",
            "40002       5  Senso Bluetooth Headphones, Best Wireless Spor...  Electronics   \n",
            "40003       5  Targus Air Traveler Laptop Backpack, Professio...  Electronics   \n",
            "40004       5  Edifier P841 Comfortable Noise Isolating Over-...  Electronics   \n",
            "\n",
            "      parent_asin  \n",
            "40000  B083NRGZMM  \n",
            "40001  B07N69T6TM  \n",
            "40002  B01G8JO5F2  \n",
            "40003  B001OC5JKY  \n",
            "40004  B07CJYMRWM  \n",
            "User Reviews DataFrame:\n",
            "   product_title   category parent_asin\n",
            "10          None  Movies_TV  B00AY5B712\n",
            "11          None  Movies_TV  B07ZWWT77T\n",
            "12          None  Movies_TV  B07XGPXPRV\n",
            "13          None  Movies_TV  B0B12GSRKP\n",
            "14          None  Movies_TV  B00AHGUCNM\n",
            "Test Reviews DataFrame:\n",
            "  product_title   category parent_asin\n",
            "0          None  Movies_TV  B00HMC4NHK\n",
            "1          None  Movies_TV  B08P7ZGLT3\n",
            "2          None  Movies_TV  B01NCHA4UW\n",
            "3          None  Movies_TV  B00A65G7X8\n",
            "4          None  Movies_TV  B084Z2FXBJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "평점이 좋은 상품중에서 유사도를 측정해서 아이템을 추천하는 방식과 순수하게 제품 제목  유사도만으로 아이템을 추천하는 방식 두가지를 사용했습니다\n",
        "\n"
      ],
      "metadata": {
        "id": "DFnf27V2tAgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations_based_on_high_rating(user_reviews_df, high_rating_products_df, tfidf_matrix, asin_to_index, category_df, top_n=5):\n",
        "    recommendations = []\n",
        "    reviewed_asins = set(user_reviews_df['parent_asin'])\n",
        "    for _, review in user_reviews_df.iterrows():\n",
        "        asin = review['parent_asin']\n",
        "        if asin not in asin_to_index:\n",
        "            continue\n",
        "        idx = asin_to_index[asin]\n",
        "        cosine_sim = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()\n",
        "        similar_indices = cosine_sim.argsort()[::-1][1:top_n+1]\n",
        "\n",
        "        similar_products_all = category_df.iloc[similar_indices]\n",
        "        similar_products = similar_products_all[similar_products_all['rating'] >= rating_threshold]\n",
        "\n",
        "        recommendations.append(similar_products)\n",
        "\n",
        "    if recommendations:\n",
        "        recommendations_df = pd.concat(recommendations).drop_duplicates()\n",
        "        recommendations_df = recommendations_df[~recommendations_df['parent_asin'].isin(reviewed_asins)]\n",
        "        recommendations_df = recommendations_df.head(top_n)\n",
        "        return recommendations_df\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def get_recommendations_based_on_similarity(user_tfidf, tfidf_matrix, category_df, user_reviews_df, asin_to_index, top_n=5):\n",
        "    cosine_sim_user = cosine_similarity(user_tfidf, tfidf_matrix).flatten()\n",
        "    user_asins = user_reviews_df['parent_asin'].tolist()\n",
        "    user_indices = [asin_to_index[asin] for asin in user_asins if asin in asin_to_index]\n",
        "    sorted_indices = cosine_sim_user.argsort()[::-1]\n",
        "    sorted_indices = [idx for idx in sorted_indices if idx not in user_indices]\n",
        "    top_indices = sorted_indices[:top_n]\n",
        "    recommended_products = category_df.iloc[top_indices]\n",
        "    return recommended_products.head(top_n)\n",
        "\n",
        "def precision_at_k(recommended_asins, val_asins, k=5):\n",
        "    recommended_top_k = recommended_asins[:k]\n",
        "    relevant = [asin for asin in recommended_top_k if asin in val_asins]\n",
        "    precision = len(relevant) / k\n",
        "    return precision\n",
        "\n",
        "def recall_at_k(recommended_asins, val_asins, k=5):\n",
        "    recommended_top_k = recommended_asins[:k]\n",
        "    relevant = [asin for asin in recommended_top_k if asin in val_asins]\n",
        "    recall = len(relevant) / len(val_asins) if len(val_asins) > 0 else 0\n",
        "    return recall\n",
        "\n"
      ],
      "metadata": {
        "id": "B9WNPRYwfcgi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "top_n = 3\n",
        "\n",
        "# 평점 데이터 타입 일관성 확인 및 변환\n",
        "filtered_products_df['rating'] = filtered_products_df['rating'].astype(float)\n",
        "for target_category in desired_categories:\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Category: {target_category}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    category_df = filtered_products_df[filtered_products_df['category'] == target_category].copy()\n",
        "    category_df['combined_text'] = combine_product_title(category_df)\n",
        "\n",
        "    category_train_reviews = train_reviews[train_reviews['category'] == target_category].copy()\n",
        "    category_val_reviews = val_reviews[val_reviews['category'] == target_category].copy()\n",
        "\n",
        "    category_train_reviews['combined_text'] = combine_product_title(category_train_reviews)\n",
        "    category_val_reviews['combined_text'] = combine_product_title(category_val_reviews)\n",
        "\n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_features=10000)\n",
        "    tfidf_matrix = tfidf.fit_transform(category_df['combined_text'])\n",
        "\n",
        "    category_df = category_df.reset_index(drop=True)\n",
        "    category_df['index'] = category_df.index\n",
        "    asin_to_index = pd.Series(category_df.index, index=category_df['parent_asin']).to_dict()\n",
        "\n",
        "    print(\"TF-IDF Matrix Shape:\", tfidf_matrix.shape)\n",
        "\n",
        "    high_rating_products_df = category_df[category_df['rating'] >= rating_threshold].copy()\n",
        "    print(f\"Number of products with rating >= {rating_threshold} in {target_category}: {len(high_rating_products_df)}\")\n",
        "\n",
        "    if len(category_train_reviews) > 0:\n",
        "        user_query = ' '.join(category_train_reviews['combined_text'].tolist())\n",
        "        user_tfidf = tfidf.transform([user_query])\n",
        "    else:\n",
        "        user_query = ''\n",
        "        user_tfidf = tfidf.transform([user_query])\n",
        "\n",
        "    val_asins = category_val_reviews['parent_asin'].unique().tolist()\n",
        "\n",
        "    # 유사도 기반 추천\n",
        "    recommended_products_similarity = get_recommendations_based_on_similarity(\n",
        "        user_tfidf, tfidf_matrix, category_df, category_train_reviews, asin_to_index, top_n=top_n\n",
        "    )\n",
        "    recommended_asins_similarity = recommended_products_similarity['parent_asin'].tolist()\n",
        "    precision_sim = precision_at_k(recommended_asins_similarity, val_asins, k=top_n)\n",
        "    recall_sim = recall_at_k(recommended_asins_similarity, val_asins, k=top_n)\n",
        "\n",
        "    print(\"순수 유사도 기반 추천 성능:\")\n",
        "    print(f\"Precision@{top_n}: {precision_sim}, Recall@{top_n}: {recall_sim}\")\n",
        "\n",
        "    # 평점 기반 추천\n",
        "    recommended_products_rating = get_recommendations_based_on_high_rating(\n",
        "        category_train_reviews, high_rating_products_df, tfidf_matrix, asin_to_index, category_df, top_n=top_n\n",
        "    )\n",
        "    if not recommended_products_rating.empty:\n",
        "        recommended_asins_rating = recommended_products_rating['parent_asin'].tolist()\n",
        "        precision_rating = precision_at_k(recommended_asins_rating, val_asins, k=top_n)\n",
        "        recall_rating = recall_at_k(recommended_asins_rating, val_asins, k=top_n)\n",
        "        print(\"평점 + 유사도 기반 추천 성능:\")\n",
        "        print(f\"Precision@{top_n}: {precision_rating}, Recall@{top_n}: {recall_rating}\")\n",
        "    else:\n",
        "        print(\"평점 + 유사도 기반 추천 결과 없음 (해당 카테고리에서 rating >= 4.5 상품 부재)\")"
      ],
      "metadata": {
        "id": "063zzAptflAW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "1465fd8e-858f-4b09-94f7-e8dd19617215"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Category: Movies_TV\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "empty vocabulary; perhaps the documents only contain stop words",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-9138c080f809>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtfidf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'combined_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcategory_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategory_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2089\u001b[0m             \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m         )\n\u001b[0;32m-> 2091\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1370\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1279\u001b[0m                     \u001b[0;34m\"empty vocabulary; perhaps the documents only contain stop words\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c8J4xmrL85Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 리뷰 데이터에 대해서는 성능 평가 없이 추천만 수행( 실제 시나리오)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"User Review 기반 추천 (성능평가 없음)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 특정사용자 데이터\n",
        "user_reviews_df['combined_text'] = combine_product_title(user_reviews_df)\n",
        "\n",
        "for target_category in desired_categories:\n",
        "    print(\"\\nCategory:\", target_category)\n",
        "    category_df = filtered_products_df[filtered_products_df['category'] == target_category].copy()\n",
        "    category_df['combined_text'] = combine_product_title(category_df)\n",
        "\n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "    tfidf_matrix = tfidf.fit_transform(category_df['combined_text'])\n",
        "\n",
        "    category_df = category_df.reset_index(drop=True)\n",
        "    category_df['index'] = category_df.index\n",
        "    asin_to_index = pd.Series(category_df.index, index=category_df['parent_asin']).to_dict()\n",
        "\n",
        "    high_rating_products_df = category_df[category_df['rating'] >= rating_threshold].copy()\n",
        "\n",
        "    user_query_all = ' '.join(user_reviews_df['combined_text'].tolist())\n",
        "    user_tfidf_all = tfidf.transform([user_query_all])\n",
        "\n",
        "    # 평점 기반 추천 (user_review)\n",
        "    recommended_products_rating_user = get_recommendations_based_on_high_rating(\n",
        "        user_reviews_df, high_rating_products_df, tfidf_matrix, asin_to_index, category_df, top_n=3\n",
        "    )\n",
        "    print(\"User Review 기반 평점 + 유사도 추천 상품:\")\n",
        "    if not recommended_products_rating_user.empty:\n",
        "        print(recommended_products_rating_user[['parent_asin', 'product_title', 'category']])\n",
        "    else:\n",
        "        print(\"추천 없음\")\n",
        "\n",
        "    # 유사도 기반 추천 (user_review)\n",
        "    recommended_products_similarity_user = get_recommendations_based_on_similarity(\n",
        "        user_tfidf_all, tfidf_matrix, category_df, user_reviews_df, asin_to_index, top_n=3\n",
        "    )\n",
        "    print(\"User Review 기반 순수 유사도 추천 상품:\")\n",
        "    print(recommended_products_similarity_user[['parent_asin', 'product_title', 'category']])"
      ],
      "metadata": {
        "id": "XAjPaWPT5AMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "애플리케이션 시나리오에서 수집할 수 있는 데이터는 사용자가 선호하는 상품의 이름, 카테고리 정도 뿐입니다 따라서  콜드스타트 문제로인해 테스트셋에서 실제로 정확한 추천을 거의 못하는 모습을 볼 수 있습니다. 만약 완전한 사용자 리뷰 데이터를 사용할 수 있을때\n",
        "title , text를 이용할 수 있을때는 그보다 나은 성능이 측정됩니다\n"
      ],
      "metadata": {
        "id": "AvQEjL3Ayr8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#사용자 리뷰데이터를 완전히 사용 가능한다는가정\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 상품 데이터 파일 경로\n",
        "products_file_path = './combined_data2.json'  # 실제 경로로 변경\n",
        "products_df = pd.read_json(products_file_path, lines=True)\n",
        "\n",
        "# 원하는 카테고리 목록\n",
        "desired_categories = ['Movies_TV', 'Grocery_Gourmet_Food','Electronics']\n",
        "\n",
        "# 카테고리 필터링\n",
        "filtered_products_df = products_df[products_df['category'].isin(desired_categories)].copy()\n",
        "filtered_products_df = filtered_products_df[['rating', 'title', 'text', 'helpful_vote',\n",
        "                                             'verified_purchase', 'product_title', 'category', 'parent_asin']]\n",
        "print(\"Filtered Products DataFrame:\")\n",
        "print(filtered_products_df.head())\n",
        "\n",
        "# user_reviews 데이터 로드\n",
        "user_reviews_file_path = './user_reviews.json'  # 실제 경로로 변경\n",
        "user_reviews_df = pd.read_json(user_reviews_file_path, lines=True)\n",
        "user_reviews_df = user_reviews_df[['title', 'text', 'helpful_vote', 'verified_purchase', 'product_title', 'category', 'parent_asin']]\n",
        "user_reviews_df = user_reviews_df[user_reviews_df['category'].isin(desired_categories)].copy()\n",
        "print(\"User Reviews DataFrame:\")\n",
        "print(user_reviews_df.head())\n",
        "\n",
        "# test_reviews 데이터 로드\n",
        "test_reviews_file_path = './test_reviews.json'  # 실제 경로로 변경\n",
        "test_reviews_df = pd.read_json(test_reviews_file_path, lines=True)\n",
        "test_reviews_df = test_reviews_df[['title', 'text', 'helpful_vote', 'verified_purchase', 'product_title', 'category', 'parent_asin']]\n",
        "test_reviews_df = test_reviews_df[test_reviews_df['category'].isin(desired_categories)].copy()\n",
        "print(\"Test Reviews DataFrame:\")\n",
        "print(test_reviews_df.head())\n",
        "\n",
        "def combine_text(df):\n",
        "    return df['title'].fillna('') + ' ' + df['text'].fillna('') + ' ' + df['product_title'].fillna('')\n",
        "\n",
        "# test_reviews를 Train/Val로 분할 (7:3)\n",
        "train_reviews, val_reviews = train_test_split(test_reviews_df, test_size=0.3, random_state=42)\n",
        "\n",
        "# 카테고리별로 TF-IDF를 계산하기 위해 각 카테고리별로 반복 수행\n",
        "rating_threshold = 4.5  # 평점 임계값을 4.5 이상으로 설정\n",
        "\n",
        "def get_recommendations_based_on_high_rating(user_reviews_df, high_rating_products_df, tfidf_matrix, asin_to_index, category_df, top_n=5):\n",
        "    recommendations = []\n",
        "    reviewed_asins = set(user_reviews_df['parent_asin'])\n",
        "    for _, review in user_reviews_df.iterrows():\n",
        "        asin = review['parent_asin']\n",
        "        if asin not in asin_to_index:\n",
        "            continue\n",
        "        idx = asin_to_index[asin]\n",
        "        cosine_sim = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()\n",
        "        similar_indices = cosine_sim.argsort()[::-1][1:top_n+1]\n",
        "\n",
        "        similar_products_all = category_df.iloc[similar_indices]\n",
        "        # 평점 비교 조건을 >=로 변경\n",
        "        similar_products = similar_products_all[similar_products_all['rating'] >= rating_threshold]\n",
        "\n",
        "        recommendations.append(similar_products)\n",
        "\n",
        "    if recommendations:\n",
        "        recommendations_df = pd.concat(recommendations).drop_duplicates()\n",
        "        recommendations_df = recommendations_df[~recommendations_df['parent_asin'].isin(reviewed_asins)]\n",
        "        recommendations_df = recommendations_df.head(top_n)\n",
        "        return recommendations_df\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def get_recommendations_based_on_similarity(user_tfidf, tfidf_matrix, category_df, user_reviews_df, asin_to_index, top_n=5):\n",
        "    cosine_sim_user = cosine_similarity(user_tfidf, tfidf_matrix).flatten()\n",
        "    user_asins = user_reviews_df['parent_asin'].tolist()\n",
        "    user_indices = [asin_to_index[asin] for asin in user_asins if asin in asin_to_index]\n",
        "    sorted_indices = cosine_sim_user.argsort()[::-1]\n",
        "    sorted_indices = [idx for idx in sorted_indices if idx not in user_indices]\n",
        "    top_indices = sorted_indices[:top_n]\n",
        "    recommended_products = category_df.iloc[top_indices]\n",
        "    return recommended_products.head(top_n)\n",
        "\n",
        "def precision_at_k(recommended_asins, val_asins, k=5):\n",
        "    recommended_top_k = recommended_asins[:k]\n",
        "    relevant = [asin for asin in recommended_top_k if asin in val_asins]\n",
        "    precision = len(relevant) / k\n",
        "    return precision\n",
        "\n",
        "def recall_at_k(recommended_asins, val_asins, k=5):\n",
        "    recommended_top_k = recommended_asins[:k]\n",
        "    relevant = [asin for asin in recommended_top_k if asin in val_asins]\n",
        "    recall = len(relevant) / len(val_asins) if len(val_asins) > 0 else 0\n",
        "    return recall\n",
        "\n",
        "top_n = 3  # 추천 개수를 5으로 설정\n",
        "\n",
        "# 평점 데이터 타입 일관성 확인 및 변환\n",
        "filtered_products_df['rating'] = filtered_products_df['rating'].astype(float)\n",
        "\n",
        "for target_category in desired_categories:\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Category: {target_category}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    category_df = filtered_products_df[filtered_products_df['category'] == target_category].copy()\n",
        "    category_df['combined_text'] = combine_text(category_df)\n",
        "\n",
        "    category_train_reviews = train_reviews[train_reviews['category'] == target_category].copy()\n",
        "    category_val_reviews = val_reviews[val_reviews['category'] == target_category].copy()\n",
        "\n",
        "    category_train_reviews['combined_text'] = combine_text(category_train_reviews)\n",
        "    category_val_reviews['combined_text'] = combine_text(category_val_reviews)\n",
        "\n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "    tfidf_matrix = tfidf.fit_transform(category_df['combined_text'])\n",
        "\n",
        "    category_df = category_df.reset_index(drop=True)\n",
        "    category_df['index'] = category_df.index\n",
        "    asin_to_index = pd.Series(category_df.index, index=category_df['parent_asin']).to_dict()\n",
        "\n",
        "    print(\"TF-IDF Matrix Shape:\", tfidf_matrix.shape)\n",
        "\n",
        "    high_rating_products_df = category_df[category_df['rating'] >= rating_threshold].copy()\n",
        "    print(f\"Number of products with rating >= {rating_threshold} in {target_category}: {len(high_rating_products_df)}\")\n",
        "\n",
        "    if len(category_train_reviews) > 0:\n",
        "        user_query = ' '.join(category_train_reviews['combined_text'].tolist())\n",
        "        user_tfidf = tfidf.transform([user_query])\n",
        "    else:\n",
        "        user_query = ''\n",
        "        user_tfidf = tfidf.transform([user_query])\n",
        "\n",
        "    val_asins = category_val_reviews['parent_asin'].unique().tolist()\n",
        "\n",
        "    # 유사도 기반 추천\n",
        "    recommended_products_similarity = get_recommendations_based_on_similarity(\n",
        "        user_tfidf, tfidf_matrix, category_df, category_train_reviews, asin_to_index, top_n=top_n\n",
        "    )\n",
        "    recommended_asins_similarity = recommended_products_similarity['parent_asin'].tolist()\n",
        "    precision_sim = precision_at_k(recommended_asins_similarity, val_asins, k=top_n)\n",
        "    recall_sim = recall_at_k(recommended_asins_similarity, val_asins, k=top_n)\n",
        "\n",
        "    print(\"순수 유사도 기반 추천 성능:\")\n",
        "    print(f\"Precision@{top_n}: {precision_sim}, Recall@{top_n}: {recall_sim}\")\n",
        "\n",
        "    # 평점 기반 추천\n",
        "    recommended_products_rating = get_recommendations_based_on_high_rating(\n",
        "        category_train_reviews, high_rating_products_df, tfidf_matrix, asin_to_index, category_df, top_n=top_n\n",
        "    )\n",
        "    if not recommended_products_rating.empty:\n",
        "        recommended_asins_rating = recommended_products_rating['parent_asin'].tolist()\n",
        "        precision_rating = precision_at_k(recommended_asins_rating, val_asins, k=top_n)\n",
        "        recall_rating = recall_at_k(recommended_asins_rating, val_asins, k=top_n)\n",
        "        print(\"평점 + 유사도 기반 추천 성능:\")\n",
        "        print(f\"Precision@{top_n}: {precision_rating}, Recall@{top_n}: {recall_rating}\")\n",
        "    else:\n",
        "        print(\"평점 + 유사도 기반 추천 결과 없음 (해당 카테고리에서 rating >= 4.5 상품 부재)\")\n",
        "\n",
        "# 사용자 리뷰 데이터에 대해서는 성능 평가 없이 추천만 수행\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"User Review 기반 추천 (성능평가 없음)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# user_reviews_df 전체를 하나의 사용자로 가정 (필요하다면 특정 사용자만 선택 가능)\n",
        "user_reviews_df['combined_text'] = combine_text(user_reviews_df)\n",
        "\n",
        "for target_category in desired_categories:\n",
        "    print(\"\\nCategory:\", target_category)\n",
        "    category_df = filtered_products_df[filtered_products_df['category'] == target_category].copy()\n",
        "    category_df['combined_text'] = combine_text(category_df)\n",
        "\n",
        "    tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "    tfidf_matrix = tfidf.fit_transform(category_df['combined_text'])\n",
        "\n",
        "    category_df = category_df.reset_index(drop=True)\n",
        "    category_df['index'] = category_df.index\n",
        "    asin_to_index = pd.Series(category_df.index, index=category_df['parent_asin']).to_dict()\n",
        "\n",
        "    high_rating_products_df = category_df[category_df['rating'] >= rating_threshold].copy()\n",
        "\n",
        "    user_query_all = ' '.join(user_reviews_df['combined_text'].tolist())\n",
        "    user_tfidf_all = tfidf.transform([user_query_all])\n",
        "\n",
        "    # 평점 기반 추천 (user_review)\n",
        "    recommended_products_rating_user = get_recommendations_based_on_high_rating(\n",
        "        user_reviews_df, high_rating_products_df, tfidf_matrix, asin_to_index, category_df, top_n=5\n",
        "    )\n",
        "    print(\"User Review 기반 평점 + 유사도 추천 상품:\")\n",
        "    if not recommended_products_rating_user.empty:\n",
        "        print(recommended_products_rating_user[['parent_asin', 'product_title', 'category']])\n",
        "    else:\n",
        "        print(\"추천 없음\")\n",
        "\n",
        "    # 유사도 기반 추천 (user_review)\n",
        "    recommended_products_similarity_user = get_recommendations_based_on_similarity(\n",
        "        user_tfidf_all, tfidf_matrix, category_df, user_reviews_df, asin_to_index, top_n=5\n",
        "    )\n",
        "    print(\"User Review 기반 순수 유사도 추천 상품:\")\n",
        "    print(recommended_products_similarity_user[['parent_asin', 'product_title', 'category']])\n"
      ],
      "metadata": {
        "id": "nWfNjEnTzCf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colaborative Filtering"
      ],
      "metadata": {
        "id": "2tXZ6rR55Beu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# local에 padnas, numpy, matplotlib, surprise, sklearn 설치필요\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "YH2Y3RN35BFm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 전처리"
      ],
      "metadata": {
        "id": "xxzSpsc85pUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_review(review_path, min_user_cnt, min_review_cnt):\n",
        "    review_df = pd.read_json(review_path, lines=True)\n",
        "    filtered_review_df = review_df[[\"parent_asin\", \"rating\", \"user_id\", \"title\", \"category\", \"product_title\"]]\n",
        "    # filtered_review_df = filtered_review_df[filtered_review_df[\"category\"] == category]\n",
        "    distinct_review_df = filtered_review_df.drop_duplicates(subset=[\"user_id\", \"parent_asin\"])\n",
        "\n",
        "    review_counts = distinct_review_df[\"parent_asin\"].value_counts()\n",
        "    user_counts = distinct_review_df['user_id'].value_counts()\n",
        "\n",
        "    result_df = distinct_review_df[(\n",
        "        (distinct_review_df['user_id'].isin(user_counts[user_counts >= min_user_cnt].index)) &\n",
        "        (distinct_review_df['parent_asin'].isin(review_counts[review_counts >= min_review_cnt].index))\n",
        "    )]\n",
        "\n",
        "    # # 리뷰 개수가 많은 순으로 정렬\n",
        "    # sorted_parent_asin = result_df[\"parent_asin\"].value_counts().index\n",
        "    # result_df = result_df.set_index(\"parent_asin\").loc[sorted_parent_asin].reset_index()\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "x79bggO55OR0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_predict(item_sim_df, train_matrix, k=5):\n",
        "    item_ids = train_matrix.index\n",
        "    user_ids = train_matrix.columns\n",
        "    predictions = np.zeros(train_matrix.shape)\n",
        "\n",
        "    for item_idx, item in enumerate(item_ids):\n",
        "        for user_idx, user in enumerate(user_ids):\n",
        "            user_ratings = train_matrix.iloc[:, user_idx].values  # 해당 사용자의 모든 평점\n",
        "            relevant_items = item_sim_df.iloc[item_idx].values  # 현재 아이템과 다른 아이템 간 유사도\n",
        "\n",
        "            # K개의 가장 유사한 이웃 선택\n",
        "            neighbors_idx = np.argsort(relevant_items)[-k:]\n",
        "            neighbors_sim = relevant_items[neighbors_idx]\n",
        "            neighbors_ratings = user_ratings[neighbors_idx]\n",
        "\n",
        "            # 가중합 계산\n",
        "            weighted_sum = np.dot(neighbors_sim, neighbors_ratings)\n",
        "            sim_sum = np.abs(neighbors_sim).sum()\n",
        "\n",
        "            if sim_sum > 0:\n",
        "                predictions[item_idx, user_idx] = weighted_sum / sim_sum\n",
        "            else:\n",
        "                # 유사도가 없는 경우 행 평균값으로 대체\n",
        "                row_mean = train_matrix.iloc[item_idx, :].mean()\n",
        "                predictions[item_idx, user_idx] = row_mean\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def knn_based_cf(df, org_df, k=5):\n",
        "    # 사용자-아이템 행렬 생성\n",
        "    item_user_matrix = df.pivot(index='parent_asin', columns='user_id', values='rating').fillna(0)\n",
        "    item_ids = item_user_matrix.index\n",
        "    user_ids = item_user_matrix.columns\n",
        "\n",
        "    if df.empty:\n",
        "        return \"Empty\",\"Empty\"\n",
        "\n",
        "    # 훈련-테스트 데이터 분할\n",
        "    trainset, testset = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 훈련 데이터로 사용자-아이템 행렬 생성\n",
        "    train_matrix = trainset.pivot(index='parent_asin', columns='user_id', values='rating').reindex(index=item_ids, columns=user_ids).fillna(0)\n",
        "    test_matrix = testset.pivot(index='parent_asin', columns='user_id', values='rating').reindex(index=item_ids, columns=user_ids).fillna(0)\n",
        "\n",
        "    # 아이템 기반 코사인 유사도 계산\n",
        "    item_sim_matrix = cosine_similarity(train_matrix)\n",
        "    np.fill_diagonal(item_sim_matrix, 0)  # 자신과의 유사도는 0으로 설정\n",
        "    item_sim_df = pd.DataFrame(item_sim_matrix, index=item_ids, columns=item_ids)\n",
        "\n",
        "    # 예측값 생성\n",
        "    predictions = knn_predict(item_sim_df, train_matrix, k)\n",
        "\n",
        "    # 테스트 세트에서 RMSE 계산\n",
        "    test_actual = test_matrix.values[test_matrix > 0]\n",
        "    test_predicted = predictions[test_matrix > 0]\n",
        "    rmse = sqrt(mean_squared_error(test_actual, test_predicted))\n",
        "\n",
        "    # 커버리지 계산\n",
        "    total_len = len(org_df['parent_asin'].unique())\n",
        "    non_zero_predictions = np.sum(predictions > 0)\n",
        "    coverage_value = non_zero_predictions / total_len\n",
        "    return rmse, coverage_value"
      ],
      "metadata": {
        "id": "bQO6i4H65u1R"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터를 전처리 할 때 파라미터로 상품별 최소 리뷰 개수와 사용자별 최소 작성 리뷰 개수를 전달해 데이터를 필터링하였다. 이는 2가지 이유가 있는데, 첫번째는 데이터의 희소성을 줄여 성능 향상을 도모하기 위해서이고, 두번째는 연산 속도를 높이기 위함이었다. 설정한 값은 각각 8로 하였다."
      ],
      "metadata": {
        "id": "k9d8neR-54rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_path = './combined_data2.json'\n",
        "review_df = pd.read_json(review_path, lines=True)\n",
        "raw_df = review_df[[\"parent_asin\", \"rating\", \"user_id\", \"title\", \"category\", \"product_title\"]]\n",
        "raw_df = raw_df.drop_duplicates(subset=[\"user_id\", \"parent_asin\"])\n",
        "review_df = preprocess_review(review_path,8,8)"
      ],
      "metadata": {
        "id": "GrAl2Hw855xs"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아이템-사용자 행렬에서 아이템 끼리의 코사인 유사도를 구한 후 K개의 근접한 이웃을 뽑아 평점 예측을 하였다. 성능 지표로는 정확성을 위한 테스트 셋과 예측으로 만들어진 행렬간의 RMSE와 다양성을 위한 전체 상품 수 중 몇 가지를 추천하는지 그 비율을 나타내는 Coverage 2가지를 채택하였다."
      ],
      "metadata": {
        "id": "7OG0y5AW6JaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하지만 처음 시도한 결과는 좋지 않았다. RMSE가 4.281과 Coverage가 48.61%라는 만족스럽지 못한 수치가 나왔다. 이는 사용한 샘플 데이터의 희소성이 높기 때문이라고 가정하고 이를 낮추는 것을 목표로 삼았다."
      ],
      "metadata": {
        "id": "tdw881Vz6Lz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 아이템 기반 CF 실행\n",
        "rmse,coverage_value = knn_based_cf(review_df,raw_df)\n",
        "print(\"KNN based\")\n",
        "print(f\"RMSE: {rmse:.3f}\")\n",
        "print(f\"Coverage: {coverage_value:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWe1pVbQ6PVU",
        "outputId": "d7567985-294b-427e-bd32-21bf75bf5106"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN based\n",
            "RMSE: 4.281\n",
            "Coverage: 48.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플 데이터의 희소성을 낮추기 위하여 작성한 리뷰가 많은 사용자 N명 또는 리뷰가 많았던 상품 N개를 골라 데이터를 조정하여 테스트해보았다. N을 20~50 범위에서 Gridsearch를 이용하여 가장 좋은 성능일 때의 파라미터를 찾았다. 그 결과, 인기 사용자는 22명, 인기 상품은 23개 일때 각각 RMSE가 3.808, 3.826이 나왔다. 이렇게 샘플 데이터를 필터링하여 희소성을 낮추자 RMSE 성능이 개선되었다. 하지만 N의 값이 커질수록 coverage는 감소하며 상품 추천의 다양성은 줄어들었다."
      ],
      "metadata": {
        "id": "uUOXFfR76RvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_hyperparameter_x(review_df, raw_df, y=50, x_range=(20, 50)):\n",
        "    best_rmse = float('inf')\n",
        "    best_params = {'x': None, 'rmse': None, 'coverage': None}\n",
        "    x_values = range(x_range[0], x_range[1] + 1)\n",
        "\n",
        "    for x in x_values:\n",
        "        # 상위 x명의 유저와 각 유저당 y개의 리뷰를 필터링\n",
        "        top_user_id = (\n",
        "            review_df['user_id']\n",
        "            .value_counts()\n",
        "            .head(x)\n",
        "            .index\n",
        "        )\n",
        "        filtered_df = (\n",
        "            review_df[review_df['user_id'].isin(top_user_id)]\n",
        "            .groupby('user_id')\n",
        "            .apply(lambda group: group.head(y))\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "\n",
        "        rmse, coverage_value = knn_based_cf(filtered_df, raw_df)\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_params = {\n",
        "                'x': x,\n",
        "                'rmse': rmse,\n",
        "                'coverage': coverage_value\n",
        "            }\n",
        "\n",
        "    return best_params\n",
        "\n",
        "# 사용 예제\n",
        "best_params = find_best_hyperparameter_x(review_df, raw_df, y=50, x_range=(20, 50))\n",
        "\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(f\"x: {best_params['x']}\")\n",
        "print(f\"RMSE: {best_params['rmse']:.3f}\")\n",
        "print(f\"Coverage: {best_params['coverage']:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx_XbNVs6Sn_",
        "outputId": "90835f86-5c68-4502-a995-f024a03ec5d6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-45-55f2607c5809>:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "x: 22\n",
            "RMSE: 3.808\n",
            "Coverage: 0.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_hyperparameter_x(review_df, raw_df, y=50, x_range=(20, 50)):\n",
        "    best_rmse = float('inf')\n",
        "    best_params = {'x': None, 'rmse': None, 'coverage': None}\n",
        "\n",
        "    x_values = range(x_range[0], x_range[1] + 1)\n",
        "\n",
        "    for x in x_values:\n",
        "        # 상위 N개의 상품과 각 상품의 y개를 필터링\n",
        "        top_item_id = (\n",
        "            review_df['parent_asin']\n",
        "            .value_counts()\n",
        "            .head(x)\n",
        "            .index\n",
        "        )\n",
        "        filtered_df = (\n",
        "            review_df[review_df['parent_asin'].isin(top_item_id)]\n",
        "            .groupby('parent_asin')\n",
        "            .apply(lambda group: group.head(y))\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "\n",
        "        rmse, coverage_value = knn_based_cf(filtered_df, raw_df)\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_params = {\n",
        "                'x': x,\n",
        "                'rmse': rmse,\n",
        "                'coverage': coverage_value\n",
        "            }\n",
        "\n",
        "    return best_params\n",
        "\n",
        "# 사용 예제\n",
        "best_params = find_best_hyperparameter_x(review_df, raw_df, y=50, x_range=(20, 50))\n",
        "\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "print(f\"x: {best_params['x']}\")\n",
        "print(f\"RMSE: {best_params['rmse']:.3f}\")\n",
        "print(f\"Coverage: {best_params['coverage']:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F31g69SM6YNW",
        "outputId": "7680c4e7-649e-4466-fcf5-1c39c2804090"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n",
            "<ipython-input-46-c7e0341740e8>:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda group: group.head(y))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n",
            "x: 23\n",
            "RMSE: 3.826\n",
            "Coverage: 3.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**surprise 라이브러리 이용**\n",
        "\n",
        "GridSearch로도 RMSE에서 좋은 성능을 얻지 못하자 자체 구현한 알고리즘의 최적화 부분에서 문제가 있을 거라는 가설을 세웠다. 그래서 surprise 라이브러리를 사용하여 다시 진행해보았다."
      ],
      "metadata": {
        "id": "XX8qcBWX7EMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise\n",
        "from surprise import Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "def prepare_data(df):\n",
        "    reader = Reader(rating_scale=(1, 5))  # 평점 범위 지정\n",
        "    data = Dataset.load_from_df(df[[\"user_id\", \"parent_asin\", \"rating\"]], reader)\n",
        "    return data\n",
        "\n",
        "def coverage(predictions, total_len):\n",
        "    recommended_items = set([pred.iid for pred in predictions])\n",
        "    return len(recommended_items) / total_len\n",
        "\n",
        "def knn_based_cf_surprise(df,org_df):\n",
        "    data = prepare_data(df)\n",
        "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 코사인 유사도를 사용한 아이템 기반 CF 모델 설정\n",
        "    sim_options = {\n",
        "        \"name\": \"cosine\",\n",
        "        \"user_based\": False,\n",
        "    }\n",
        "    algo = KNNBasic(sim_options=sim_options)\n",
        "    algo.fit(trainset)\n",
        "\n",
        "    predictions = algo.test(testset)\n",
        "    # RMSE 계산\n",
        "    rmse = accuracy.rmse(predictions)\n",
        "\n",
        "    # Coverage 계산\n",
        "    total_len = len(org_df['parent_asin'].unique())\n",
        "    coverage_value = coverage(predictions, total_len)\n",
        "\n",
        "    return rmse,coverage_value,trainset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "likWyAKG7Ox5",
        "outputId": "562905f3-b79f-4791-e7de-e05526fa30cd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: surprise in /usr/local/lib/python3.10/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (from surprise) (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "surprise 라이브러리를 사용하니 RMSE가 1.219으로 줄었으나 coverage가 0.36%로 매우 낮아졌다. 이는 처음에 데이터 전처리를 할 때 파라미터(상품별 최소 리뷰 개수, 사용자별 최소 작성 리뷰 개수)를 각각 8개로 설정해 필터링했는데 surprise 라이브러리를 사용하니 다양성이 크게 훼손되었다. 하지만 RMSE 성능이 개선되었고 연산속도가 빨라져 더 큰 데이터를 처리할 수 있다고 판단하여 데이터 전처리 과정에서 파라미터를 2,2로 설정하여 성능을 다시 측정하였다. 그 결과 RMSE가 1.242, Coverage가 5.00%라는 좋은 성능을 얻을 수 있었다."
      ],
      "metadata": {
        "id": "_reVy7DD7hRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse,coverage_value,trainset = knn_based_cf_surprise(review_df,raw_df)\n",
        "print(\"KNN based\")\n",
        "print(f\"RMSE: {rmse:.3f}\")\n",
        "print(f\"Coverage: {coverage_value:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhrnRFNa7lcG",
        "outputId": "9b7e5f05-9691-4573-f89a-cf262954490d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.2190\n",
            "KNN based\n",
            "RMSE: 1.219\n",
            "Coverage: 0.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_review_df = preprocess_review(review_path,2,2)\n",
        "rmse,coverage_value,trainset = knn_based_cf_surprise(new_review_df,raw_df)\n",
        "print(\"KNN based\")\n",
        "print(f\"RMSE: {rmse:.3f}\")\n",
        "print(f\"Coverage: {coverage_value:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7LBXo8k7mk4",
        "outputId": "f7833897-8357-49e5-edcd-9176ba46376e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.2421\n",
            "KNN based\n",
            "RMSE: 1.242\n",
            "Coverage: 5.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 추가적인 성능 개선을 위하여 KNN에 기반한 Memory based 방식의 CF가 아닌, SVD에 기반한 Model based 방식의 CF를 적용해보았다. 그 결과 RMSE가 1.143으로 개선된 것을 확인할 수 있었다. 이는 데이터의 희소성을 해소했기 때문이다."
      ],
      "metadata": {
        "id": "lrSiiwpn7sLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD\n",
        "\n",
        "def svd_based_cf(df,org_df):\n",
        "    data = prepare_data(df)\n",
        "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "    algo = SVD(n_factors=10, random_state=42)\n",
        "    algo.fit(trainset)\n",
        "    predictions = algo.test(testset)\n",
        "\n",
        "    # RMSE 계산\n",
        "    rmse = accuracy.rmse(predictions)\n",
        "\n",
        "    # Coverage 계산\n",
        "    total_len = len(org_df['parent_asin'].unique())\n",
        "    coverage_value = coverage(predictions, total_len)\n",
        "    return rmse, coverage_value\n",
        "\n",
        "rmse,coverage_value = svd_based_cf(new_review_df,raw_df)\n",
        "print(\"SVD based\")\n",
        "print(f\"RMSE: {rmse:.3f}\")\n",
        "print(f\"Coverage: {coverage_value:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSEiyr-U7tR8",
        "outputId": "69b392da-70a8-47fe-d5fb-6143e3af8319"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 1.1430\n",
            "SVD based\n",
            "RMSE: 1.143\n",
            "Coverage: 5.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제 시나리오\n",
        "\n",
        "1. 카테고리 입력\n",
        "2. 해당 카테고리 인기 상품 5개 추출\n",
        "3. 5개 상품에 대하여 각각 추천하여 유사도 높은 순으로 정렬"
      ],
      "metadata": {
        "id": "oGdIvekD72eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력한 카테고리에서 인기 상품을 추천하는 함수\n",
        "def CategoryBasedRecommend(review_df, targetCategory, top_n=5):\n",
        "\n",
        "    filtered_df = review_df[review_df[\"category\"] == targetCategory]\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        print(f\"카테고리 '{targetCategory}'에 해당하는 데이터가 없습니다.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    popular_items = (\n",
        "        filtered_df.groupby([\"parent_asin\", \"category\",\"product_title\"])\n",
        "        .agg(avg_rating=(\"rating\", \"mean\"), num_reviews=(\"user_id\", \"count\"))\n",
        "        .reset_index()\n",
        "        .sort_values(by=[\"num_reviews\", \"avg_rating\"], ascending=[False, False])\n",
        "    )\n",
        "    top_items = popular_items.head(top_n)\n",
        "    return top_items"
      ],
      "metadata": {
        "id": "qQfZBXuz75FR"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 상품과 관련된 추천 5개 생성\n",
        "def recommend_related_items(df, target_item, top_n=5):\n",
        "    data = prepare_data(df)\n",
        "    trainset = data.build_full_trainset()\n",
        "    algo = SVD(n_factors=50, random_state=42)\n",
        "    algo.fit(trainset)\n",
        "    item_factors = algo.qi\n",
        "    item_ids = trainset._raw2inner_id_items.keys()\n",
        "\n",
        "    item_factors_df = pd.DataFrame(item_factors, index=item_ids)\n",
        "\n",
        "    if target_item not in item_factors_df.index:\n",
        "        raise ValueError(f\"Target item {target_item} not found in training data.\")\n",
        "    target_vector = item_factors_df.loc[target_item].values.reshape(1, -1)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarities = cosine_similarity(target_vector, item_factors_df.values).flatten()\n",
        "\n",
        "    # 유사도를 데이터프레임으로 변환\n",
        "    similarity_df = pd.DataFrame({\n",
        "        \"parent_asin\": item_factors_df.index,\n",
        "        \"similarity\": similarities\n",
        "    })\n",
        "\n",
        "    # 대상 아이템 제외 및 상위 N개 추천\n",
        "    top_related_items = similarity_df[similarity_df[\"parent_asin\"] != target_item] \\\n",
        "        .sort_values(by=\"similarity\", ascending=False) \\\n",
        "        .head(top_n)\n",
        "\n",
        "    # 추천 결과에 상품 정보 병합\n",
        "    related_items_df = top_related_items.merge(\n",
        "        df[[\"parent_asin\", \"product_title\", \"category\"]].drop_duplicates(), on=\"parent_asin\", how=\"left\"\n",
        "    )\n",
        "\n",
        "    return related_items_df"
      ],
      "metadata": {
        "id": "D5dA6Thp755j"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_category in desired_categories:\n",
        "  top_items = CategoryBasedRecommend(new_review_df,input_category)\n",
        "  recommend_result = []\n",
        "  for _, row in top_items.iterrows():\n",
        "      target_item = row[\"parent_asin\"]\n",
        "      target_category = row[\"category\"]\n",
        "      result = recommend_related_items(new_review_df, target_item)\n",
        "      for _, recommend_row in result.iterrows():\n",
        "          recommended_asin = recommend_row[\"parent_asin\"]\n",
        "          if recommended_asin not in [item[\"parent_asin\"] for item in recommend_result]:\n",
        "              recommend_result.append({\n",
        "                  \"parent_asin\": recommended_asin,\n",
        "                  \"product_title\": recommend_row[\"product_title\"],\n",
        "                  \"category\": recommend_row[\"category\"],\n",
        "                  \"similarity\": recommend_row[\"similarity\"]\n",
        "              })\n",
        "\n",
        "  sorted_recommendations = sorted(recommend_result, key=lambda x: x[\"similarity\"], reverse=True)[:5]\n",
        "\n",
        "  print(\"Input Category : \",input_category,\"\\n\")\n",
        "\n",
        "  print(\"Top 5 Recommended Items:\")\n",
        "  for item in sorted_recommendations:\n",
        "      print(f\"Parent ASIN: {item['parent_asin']}\")\n",
        "      print(f\"Product Title: {item['product_title']}\")\n",
        "      print(f\"Category: {item['category']}\")\n",
        "      print(f\"Similarity: {item['similarity']:.3f}\")\n",
        "      print(\"-\" * 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cBXRLEl78YL",
        "outputId": "300b036e-1408-48be-829c-61a58cd0baa0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Category :  Movies_TV \n",
            "\n",
            "Top 5 Recommended Items:\n",
            "Parent ASIN: B00OH8SGFC\n",
            "Product Title: Vera\n",
            "Category: Movies_TV\n",
            "Similarity: 0.524\n",
            "------------------------------\n",
            "Parent ASIN: B07JZB74TD\n",
            "Product Title: My Talking Tom 2\n",
            "Category: Software\n",
            "Similarity: 0.516\n",
            "------------------------------\n",
            "Parent ASIN: B077D4921Z\n",
            "Product Title: Magnet Eyelashes-Dual Magnetic False Eyelashes with NO GLUE 3D Fiber Reusable Best Fake Lashes Extension for Natural Look,Perfect for Deep Set Eyes (-2 Pair/8 Pieces)\n",
            "Category: Beauty\n",
            "Similarity: 0.501\n",
            "------------------------------\n",
            "Parent ASIN: B00A0RUGPM\n",
            "Product Title: KISS Heat Resistant Hair Tools Mat, 100% Silicone Protection up to 480°F, Non-Slip, Weight 0.45 Pounds, 10 inches x 10 inches, Black\n",
            "Category: Beauty\n",
            "Similarity: 0.488\n",
            "------------------------------\n",
            "Parent ASIN: B001F42MKG\n",
            "Product Title: Logitech Trackman Marble Trackball – Wired USB Ergonomic Mouse for Computers, with 4 Programmable Buttons, Dark Gray\n",
            "Category: Electronics\n",
            "Similarity: 0.484\n",
            "------------------------------\n",
            "Input Category :  Grocery_Gourmet_Food \n",
            "\n",
            "Top 5 Recommended Items:\n",
            "Parent ASIN: B072V478NR\n",
            "Product Title: Amazon Basics Carrying Case for Nintendo Switch - Black\n",
            "Category: Video_Games\n",
            "Similarity: 0.582\n",
            "------------------------------\n",
            "Parent ASIN: B0BNTLCS7N\n",
            "Product Title: Annie Chun's - Noodle Soup Bowl, Japanese Style Miso, Instant & Microwaveable Noodles, Vegan, Hearty and Delicious, 5.9 Oz (Pack of 6)\n",
            "Category: Grocery_Gourmet_Food\n",
            "Similarity: 0.520\n",
            "------------------------------\n",
            "Parent ASIN: B01FF96B94\n",
            "Product Title: CARNATION Half n Half 360x .304 fl oz US\n",
            "Category: Grocery_Gourmet_Food\n",
            "Similarity: 0.499\n",
            "------------------------------\n",
            "Parent ASIN: B07MQFPDSS\n",
            "Product Title: Fitbit Inspire Fitness Tracker, One Size (S and L Bands Included)\n",
            "Category: Sports_Outdoors\n",
            "Similarity: 0.489\n",
            "------------------------------\n",
            "Parent ASIN: B08SG6K56D\n",
            "Product Title: ZIXMMO OEM Quality 28in + 16in Premium All-Season Windshield Wiper Blades for Original Equipment Replacement(Set of 2)\n",
            "Category: Car\n",
            "Similarity: 0.485\n",
            "------------------------------\n",
            "Input Category :  Electronics \n",
            "\n",
            "Top 5 Recommended Items:\n",
            "Parent ASIN: B00LML7GJY\n",
            "Product Title: Wagan EL8324 Wagan Tech Solar e Charger Dex\n",
            "Category: Car\n",
            "Similarity: 0.582\n",
            "------------------------------\n",
            "Parent ASIN: B07VGQFZB7\n",
            "Product Title: Louis Pelle Hand Painted Leather Triple Zip Pocket Crossbody Bag For Women Original Art Work\n",
            "Category: Fashion\n",
            "Similarity: 0.522\n",
            "------------------------------\n",
            "Parent ASIN: B07T64WW7P\n",
            "Product Title: ORDA Wireless Controller Compatible with PS4, Wireless Gamepad for PC (7/8/8.1/10) with Vibration and Audio Function, Mini LED Indicator, USB Cable and Anti-Slip\n",
            "Category: Video_Games\n",
            "Similarity: 0.518\n",
            "------------------------------\n",
            "Parent ASIN: B07L1XW8W3\n",
            "Product Title: 4 XL Surprise Bath Bombs Gift Set - Made in The USA - Kids Bath Bombs with Surprises Inside - Bath Bombs Gift Set for Girls & Boys -\n",
            "Category: Beauty\n",
            "Similarity: 0.512\n",
            "------------------------------\n",
            "Parent ASIN: B00KVQQHNM\n",
            "Product Title: Turtle Beach Ear Force Heroes of the Storm Gaming Headset for PC and Mobile Devices\n",
            "Category: Video_Games\n",
            "Similarity: 0.502\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}